{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.4.1 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: tensorflow-gpu==2.4.1 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (4.5.3.56)\n",
      "Requirement already satisfied: mediapipe in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (0.8.6.2)\n",
      "Requirement already satisfied: sklearn in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (3.7.4.3)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (0.3.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (1.19.2)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (1.12.1)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (1.6.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (1.1.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (2.10.0)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (1.15.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (0.35.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (3.17.3)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (1.32.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (0.2.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (0.13.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (1.12)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (3.3.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (2.5.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (2.4.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from mediapipe) (20.3.0)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from mediapipe) (4.5.3.56)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from matplotlib) (8.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from matplotlib) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.5)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.24.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.34.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (50.3.1.post20201107)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.1.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.2; however, version 21.2.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\21smt17\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (0.5.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.2; however, version 21.2.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\21smt17\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 opencv-python mediapipe sklearn matplotlib\n",
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding:utf-8-*-\n",
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic #Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                   # Image is no longer writeable\n",
    "    results = model.process(image)                  # Make prediction\n",
    "    image.flags.writeable = True                    # Image is now writeable\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # COLOR CONVERSION RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS) # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({(<PoseLandmark.NOSE: 0>, <PoseLandmark.LEFT_EYE_INNER: 1>),\n",
       "           (<PoseLandmark.NOSE: 0>, <PoseLandmark.RIGHT_EYE_INNER: 4>),\n",
       "           (<PoseLandmark.LEFT_EYE_INNER: 1>, <PoseLandmark.LEFT_EYE: 2>),\n",
       "           (<PoseLandmark.LEFT_EYE: 2>, <PoseLandmark.LEFT_EYE_OUTER: 3>),\n",
       "           (<PoseLandmark.LEFT_EYE_OUTER: 3>, <PoseLandmark.LEFT_EAR: 7>),\n",
       "           (<PoseLandmark.RIGHT_EYE_INNER: 4>, <PoseLandmark.RIGHT_EYE: 5>),\n",
       "           (<PoseLandmark.RIGHT_EYE: 5>, <PoseLandmark.RIGHT_EYE_OUTER: 6>),\n",
       "           (<PoseLandmark.RIGHT_EYE_OUTER: 6>, <PoseLandmark.RIGHT_EAR: 8>),\n",
       "           (<PoseLandmark.MOUTH_RIGHT: 10>, <PoseLandmark.MOUTH_LEFT: 9>),\n",
       "           (<PoseLandmark.LEFT_SHOULDER: 11>, <PoseLandmark.LEFT_ELBOW: 13>),\n",
       "           (<PoseLandmark.LEFT_SHOULDER: 11>, <PoseLandmark.LEFT_HIP: 23>),\n",
       "           (<PoseLandmark.RIGHT_SHOULDER: 12>,\n",
       "            <PoseLandmark.LEFT_SHOULDER: 11>),\n",
       "           (<PoseLandmark.RIGHT_SHOULDER: 12>, <PoseLandmark.RIGHT_ELBOW: 14>),\n",
       "           (<PoseLandmark.RIGHT_SHOULDER: 12>, <PoseLandmark.RIGHT_HIP: 24>),\n",
       "           (<PoseLandmark.LEFT_ELBOW: 13>, <PoseLandmark.LEFT_WRIST: 15>),\n",
       "           (<PoseLandmark.RIGHT_ELBOW: 14>, <PoseLandmark.RIGHT_WRIST: 16>),\n",
       "           (<PoseLandmark.LEFT_WRIST: 15>, <PoseLandmark.LEFT_PINKY: 17>),\n",
       "           (<PoseLandmark.LEFT_WRIST: 15>, <PoseLandmark.LEFT_INDEX: 19>),\n",
       "           (<PoseLandmark.LEFT_WRIST: 15>, <PoseLandmark.LEFT_THUMB: 21>),\n",
       "           (<PoseLandmark.RIGHT_WRIST: 16>, <PoseLandmark.RIGHT_PINKY: 18>),\n",
       "           (<PoseLandmark.RIGHT_WRIST: 16>, <PoseLandmark.RIGHT_INDEX: 20>),\n",
       "           (<PoseLandmark.RIGHT_WRIST: 16>, <PoseLandmark.RIGHT_THUMB: 22>),\n",
       "           (<PoseLandmark.LEFT_PINKY: 17>, <PoseLandmark.LEFT_INDEX: 19>),\n",
       "           (<PoseLandmark.RIGHT_PINKY: 18>, <PoseLandmark.RIGHT_INDEX: 20>),\n",
       "           (<PoseLandmark.LEFT_HIP: 23>, <PoseLandmark.LEFT_KNEE: 25>),\n",
       "           (<PoseLandmark.RIGHT_HIP: 24>, <PoseLandmark.LEFT_HIP: 23>),\n",
       "           (<PoseLandmark.RIGHT_HIP: 24>, <PoseLandmark.RIGHT_KNEE: 26>),\n",
       "           (<PoseLandmark.LEFT_KNEE: 25>, <PoseLandmark.LEFT_ANKLE: 27>),\n",
       "           (<PoseLandmark.RIGHT_KNEE: 26>, <PoseLandmark.RIGHT_ANKLE: 28>),\n",
       "           (<PoseLandmark.LEFT_ANKLE: 27>, <PoseLandmark.LEFT_HEEL: 29>),\n",
       "           (<PoseLandmark.LEFT_ANKLE: 27>, <PoseLandmark.LEFT_FOOT_INDEX: 31>),\n",
       "           (<PoseLandmark.RIGHT_ANKLE: 28>, <PoseLandmark.RIGHT_HEEL: 30>),\n",
       "           (<PoseLandmark.RIGHT_ANKLE: 28>,\n",
       "            <PoseLandmark.RIGHT_FOOT_INDEX: 32>),\n",
       "           (<PoseLandmark.LEFT_HEEL: 29>, <PoseLandmark.LEFT_FOOT_INDEX: 31>),\n",
       "           (<PoseLandmark.RIGHT_HEEL: 30>,\n",
       "            <PoseLandmark.RIGHT_FOOT_INDEX: 32>)})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_holistic.POSE_CONNECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "#     mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS,\n",
    "#                              mp_drawing.DrawingSpec(color=(80,110,10), thickness=1,circle_radius=1),\n",
    "#                              mp_drawing.DrawingSpec(color=(80,265,121), thickness=1,circle_radius=1)\n",
    "#                              ) # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2,circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2,circle_radius=2)) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2,circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2,circle_radius=2)) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(245,117,6), thickness=2,circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2,circle_radius=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "#cap = cv2.VideoCapture(0)\n",
    "# for i in range(0,3):\n",
    "cap = cv2.VideoCapture(\"./img/NIA_SL_WORD2751_REAL01_F.mp4\")\n",
    "#cap = cv2.VideoCapture(\"./img/T1.mp4\")\n",
    "#cap = cv2.VideoCapture(0)\n",
    "# for i in range(0,2,1):\n",
    "#     cap = cv2.VideoCapture(\"./img/KETI_SL_000000000\"+\"{}.avi\".format(i + 2))\n",
    "    \n",
    "# Set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        \n",
    "    \n",
    "        # Read feed        \n",
    "        ret, frame = cap.read()\n",
    "        #frame = imutils.resize(frame, width=1200)\n",
    "#         if not ret:\n",
    "#             print(\"비디오 읽기 실패 / 비디오 모두 읽음\")\n",
    "#             cap.release()   # 비디오 읽기 종료\n",
    "#             cv2.destroyAllWindows()  # 새로 연 창을 모두 닫아줌\n",
    "#             break\n",
    "        # Make detections(탐지들)\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        print(results)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "        \n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "        \n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results.left_hand_landmarks.landmark\n",
    "len(results.right_hand_landmarks.landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(draw_landmarks(frame, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-beea7e0dea11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisibility\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "pose = []\n",
    "for res in results.pose_landmarks.landmark:\n",
    "    test = np.array([res.x, res.y, res.z, res.visibility])\n",
    "    pose.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-9cc71c7658eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#len(pose)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#pose = np.array([[res.x, res.y, res.z, res.visibility(저항)] for res in results.pose_landmarks.landmark])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisibility\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m132\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mface\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface_landmarks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface_landmarks\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1404\u001b[0m\u001b[1;33m)\u001b[0m                                                                                                   \u001b[1;31m# 학습시킬려고 flatten으로 쫙 펴줌\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mlh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_hand_landmarks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_hand_landmarks\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "#test\n",
    "#pose\n",
    "#len(pose)\n",
    "#pose = np.array([[res.x, res.y, res.z, res.visibility(저항)] for res in results.pose_landmarks.landmark])\n",
    "pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)\n",
    "face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(1404)                                                                                                   # 학습시킬려고 flatten으로 쫙 펴줌\n",
    "lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "   pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "#    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)                                                                                                   # 학습시킬려고 flatten으로 쫙 펴줌\n",
    "   lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "   rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3) \n",
    "   return np.concatenate([pose, lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(results.face_landmarks.landmark) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.87624180e-01,  5.90588450e-01, -1.27639378e-05,  7.32757986e-01,\n",
       "        5.63510776e-01, -2.18620580e-02,  6.96821928e-01,  4.99367177e-01,\n",
       "       -2.80388817e-02,  6.79750443e-01,  4.44291949e-01, -3.68351899e-02,\n",
       "        6.61758244e-01,  4.09160078e-01, -4.73118275e-02,  7.32539117e-01,\n",
       "        4.13816422e-01, -2.62080715e-03,  7.15683818e-01,  3.48913789e-01,\n",
       "       -1.35451937e-02,  7.08856881e-01,  3.08455646e-01, -2.92565413e-02,\n",
       "        7.04533815e-01,  2.71846175e-01, -4.13230211e-02,  7.67735243e-01,\n",
       "        4.03414756e-01, -6.68242434e-03,  7.65343547e-01,  3.27461600e-01,\n",
       "       -7.06402212e-03,  7.64405072e-01,  2.82331020e-01, -2.58288998e-02,\n",
       "        7.64607012e-01,  2.42570475e-01, -4.26378474e-02,  8.00397635e-01,\n",
       "        4.11205709e-01, -1.57206282e-02,  8.04747045e-01,  3.38915735e-01,\n",
       "       -2.34648623e-02,  8.08072507e-01,  2.93832213e-01, -4.60261703e-02,\n",
       "        8.11098933e-01,  2.54201174e-01, -6.53683841e-02,  8.32200646e-01,\n",
       "        4.34135377e-01, -2.68993080e-02,  8.51750076e-01,  3.84301722e-01,\n",
       "       -4.06119414e-02,  8.63831401e-01,  3.51929933e-01, -5.81320934e-02,\n",
       "        8.74227107e-01,  3.20792586e-01, -7.45713264e-02])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.48925254e-01,  5.37759066e-01, -6.20893406e-05,  2.96656460e-01,\n",
       "        5.11519849e-01, -1.41496677e-02,  3.31023455e-01,  4.44971025e-01,\n",
       "       -1.74512174e-02,  3.46047491e-01,  3.89703631e-01, -2.43842304e-02,\n",
       "        3.61301988e-01,  3.54035109e-01, -3.08846217e-02,  2.92173713e-01,\n",
       "        3.59226912e-01,  4.01701033e-03,  3.06869388e-01,  2.97041684e-01,\n",
       "       -8.21058080e-03,  3.14848453e-01,  2.59150952e-01, -1.39177172e-02,\n",
       "        3.20684433e-01,  2.23777384e-01, -1.69139933e-02,  2.60454178e-01,\n",
       "        3.50561589e-01, -2.83411238e-03,  2.64055759e-01,  2.81485975e-01,\n",
       "       -1.26298349e-02,  2.66730905e-01,  2.37022266e-01, -2.14153882e-02,\n",
       "        2.70159036e-01,  1.99702352e-01, -2.79093646e-02,  2.31591225e-01,\n",
       "        3.57781678e-01, -1.56562105e-02,  2.27402925e-01,  2.90376872e-01,\n",
       "       -2.97476016e-02,  2.25016832e-01,  2.44542018e-01, -4.23591547e-02,\n",
       "        2.26317734e-01,  2.04151556e-01, -5.18308319e-02,  2.03081071e-01,\n",
       "        3.81299734e-01, -3.08964849e-02,  1.86174393e-01,  3.32167119e-01,\n",
       "       -4.27421369e-02,  1.74481258e-01,  2.98036456e-01, -5.35714515e-02,\n",
       "        1.65529758e-01,  2.64600188e-01, -6.49069697e-02])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(21*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract_keypoints(results).shape\n",
    "result_test = extract_keypoints(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.81343031e-01,  3.27566653e-01, -7.51166224e-01,  9.99939740e-01,\n",
       "        4.99387085e-01,  2.64320821e-01, -7.33469605e-01,  9.99800563e-01,\n",
       "        5.12962699e-01,  2.61591166e-01, -7.32538760e-01,  9.99847114e-01,\n",
       "        5.27027607e-01,  2.58902639e-01, -7.32432008e-01,  9.99776840e-01,\n",
       "        4.62890327e-01,  2.75043547e-01, -7.10544765e-01,  9.99767244e-01,\n",
       "        4.49713558e-01,  2.79371083e-01, -7.11447179e-01,  9.99815404e-01,\n",
       "        4.34669316e-01,  2.83112168e-01, -7.11935639e-01,  9.99744952e-01,\n",
       "        5.59696496e-01,  2.81309515e-01, -4.48252439e-01,  9.99887586e-01,\n",
       "        4.25332159e-01,  3.07427466e-01, -3.44777316e-01,  9.99880731e-01,\n",
       "        5.19158959e-01,  3.91484946e-01, -6.32072628e-01,  9.99883354e-01,\n",
       "        4.69446748e-01,  4.04630661e-01, -6.02522194e-01,  9.99906778e-01,\n",
       "        7.07498848e-01,  5.71144879e-01, -2.20750213e-01,  9.99823749e-01,\n",
       "        3.28724980e-01,  5.75886488e-01, -1.28167927e-01,  9.99811471e-01,\n",
       "        8.41926217e-01,  9.52793002e-01, -7.58953631e-01,  9.32125330e-01,\n",
       "        1.67375073e-01,  9.31833386e-01, -6.49985373e-01,  9.63637412e-01,\n",
       "        8.13607872e-01,  6.17309690e-01, -1.41463053e+00,  9.94740844e-01,\n",
       "        2.50119865e-01,  5.42331517e-01, -1.38508677e+00,  9.97465193e-01,\n",
       "        8.13686013e-01,  4.90583450e-01, -1.49163747e+00,  9.92883563e-01,\n",
       "        2.45312765e-01,  4.32893783e-01, -1.51650977e+00,  9.95122671e-01,\n",
       "        7.90975273e-01,  4.36083496e-01, -1.37952948e+00,  9.92994428e-01,\n",
       "        2.74486601e-01,  3.95548046e-01, -1.39926684e+00,  9.94992614e-01,\n",
       "        7.71643758e-01,  4.98657882e-01, -1.37527072e+00,  9.91370797e-01,\n",
       "        3.03043008e-01,  4.43750292e-01, -1.36729920e+00,  9.93917286e-01,\n",
       "        6.37993813e-01,  1.30033517e+00, -8.22381526e-02,  3.93572496e-03,\n",
       "        3.61862838e-01,  1.29327404e+00,  8.59833807e-02,  4.49032243e-03,\n",
       "        6.27521634e-01,  1.88217509e+00,  7.29894638e-03,  5.24198695e-04,\n",
       "        3.60624492e-01,  1.87576306e+00,  1.15630150e-01,  5.57471823e-04,\n",
       "        6.26564562e-01,  2.42195153e+00,  6.32383704e-01,  6.00789390e-05,\n",
       "        3.84503365e-01,  2.41280150e+00,  4.65490520e-01,  4.92994404e-05,\n",
       "        6.34091258e-01,  2.49810863e+00,  6.90686285e-01,  6.54466785e-05,\n",
       "        3.84602219e-01,  2.48923755e+00,  4.99481201e-01,  7.33838751e-05,\n",
       "        5.86770535e-01,  2.59061050e+00,  3.67858410e-01,  1.39777563e-04,\n",
       "        4.13223326e-01,  2.57845950e+00,  6.53635338e-02,  1.55122165e-04,\n",
       "        7.87624180e-01,  5.90588450e-01, -1.27639378e-05,  7.32757986e-01,\n",
       "        5.63510776e-01, -2.18620580e-02,  6.96821928e-01,  4.99367177e-01,\n",
       "       -2.80388817e-02,  6.79750443e-01,  4.44291949e-01, -3.68351899e-02,\n",
       "        6.61758244e-01,  4.09160078e-01, -4.73118275e-02,  7.32539117e-01,\n",
       "        4.13816422e-01, -2.62080715e-03,  7.15683818e-01,  3.48913789e-01,\n",
       "       -1.35451937e-02,  7.08856881e-01,  3.08455646e-01, -2.92565413e-02,\n",
       "        7.04533815e-01,  2.71846175e-01, -4.13230211e-02,  7.67735243e-01,\n",
       "        4.03414756e-01, -6.68242434e-03,  7.65343547e-01,  3.27461600e-01,\n",
       "       -7.06402212e-03,  7.64405072e-01,  2.82331020e-01, -2.58288998e-02,\n",
       "        7.64607012e-01,  2.42570475e-01, -4.26378474e-02,  8.00397635e-01,\n",
       "        4.11205709e-01, -1.57206282e-02,  8.04747045e-01,  3.38915735e-01,\n",
       "       -2.34648623e-02,  8.08072507e-01,  2.93832213e-01, -4.60261703e-02,\n",
       "        8.11098933e-01,  2.54201174e-01, -6.53683841e-02,  8.32200646e-01,\n",
       "        4.34135377e-01, -2.68993080e-02,  8.51750076e-01,  3.84301722e-01,\n",
       "       -4.06119414e-02,  8.63831401e-01,  3.51929933e-01, -5.81320934e-02,\n",
       "        8.74227107e-01,  3.20792586e-01, -7.45713264e-02,  2.48925254e-01,\n",
       "        5.37759066e-01, -6.20893406e-05,  2.96656460e-01,  5.11519849e-01,\n",
       "       -1.41496677e-02,  3.31023455e-01,  4.44971025e-01, -1.74512174e-02,\n",
       "        3.46047491e-01,  3.89703631e-01, -2.43842304e-02,  3.61301988e-01,\n",
       "        3.54035109e-01, -3.08846217e-02,  2.92173713e-01,  3.59226912e-01,\n",
       "        4.01701033e-03,  3.06869388e-01,  2.97041684e-01, -8.21058080e-03,\n",
       "        3.14848453e-01,  2.59150952e-01, -1.39177172e-02,  3.20684433e-01,\n",
       "        2.23777384e-01, -1.69139933e-02,  2.60454178e-01,  3.50561589e-01,\n",
       "       -2.83411238e-03,  2.64055759e-01,  2.81485975e-01, -1.26298349e-02,\n",
       "        2.66730905e-01,  2.37022266e-01, -2.14153882e-02,  2.70159036e-01,\n",
       "        1.99702352e-01, -2.79093646e-02,  2.31591225e-01,  3.57781678e-01,\n",
       "       -1.56562105e-02,  2.27402925e-01,  2.90376872e-01, -2.97476016e-02,\n",
       "        2.25016832e-01,  2.44542018e-01, -4.23591547e-02,  2.26317734e-01,\n",
       "        2.04151556e-01, -5.18308319e-02,  2.03081071e-01,  3.81299734e-01,\n",
       "       -3.08964849e-02,  1.86174393e-01,  3.32167119e-01, -4.27421369e-02,\n",
       "        1.74481258e-01,  2.98036456e-01, -5.35714515e-02,  1.65529758e-01,\n",
       "        2.64600188e-01, -6.49069697e-02])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1662"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "468*3+33*4+21*3+21*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-5c00075758a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 딥러닝 파일에 0.npy 파일 생김   test용\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'result_test' is not defined"
     ]
    }
   ],
   "source": [
    "# 딥러닝 파일에 0.npy 파일 생김   test용\n",
    "np.save('0', result_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('수어테스트1')\n",
    "\n",
    "# Actions that we try to detect\n",
    "#actions = np.array(['coco','love','HM'])\n",
    "#actions = np.array(['T1','T2','T3','T4','T5','T6','T7','T8','T9','T10','T11','T12'])\n",
    "actions = np.array(['감사합니다','귀여워요','괜찮아요','미안합니다','기다려요'])\n",
    "# Thirty videos worth of data\n",
    "no_sequences =  20#60#10      #29 , 16, 5\n",
    "\n",
    "# videos are going to be 30 frames in length\n",
    "sequence_length = 40#40#50    #30, 20, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더 세개 생성!! 딥러닝 -> 안녕, 나는, 아가형민 순서대로 생김\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        try:\n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "        except :\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)    \n",
    "    # Set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "#     for action in actions:        \n",
    "    # New Loop\n",
    "    # Loop through actions\n",
    "        \n",
    "\n",
    "        # Loop through sequences aka videos\n",
    "\n",
    "    for action in actions:\n",
    "        for i in range(0,20,1):        \n",
    "            for frame_num in range(sequence_length):                \n",
    "\n",
    "                # read feed\n",
    "                ret, frame = cap.read()\n",
    "                #frame = imutils.resize(frame, width=800)\n",
    "                # Make detections\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "    #                print(results)\n",
    "\n",
    "                # Draw landmarks\n",
    "                draw_styled_landmarks(image, results)\n",
    "\n",
    "                # New Apply wait logic\n",
    "                if frame_num == 0:\n",
    "                    cv2.putText(image, 'STRATING COLLECTION', (120,200),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 4, cv2.LINE_AA)\n",
    "                    cv2.putText(image, 'Collecting frames for {} Video Number{} f_num{}'.format(action, i,frame_num), (15,12),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1, cv2.LINE_AA)\n",
    "                        # show to screen\n",
    "\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                    cv2.waitKey(1000) # 1000\n",
    "\n",
    "                else : \n",
    "                    cv2.putText(image, 'Collecting frames for {} Video Number{} f_num{}'.format(action, i, frame_num), (15,12),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1, cv2.LINE_AA)\n",
    "                        # show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "                # NEW Export keypoints\n",
    "                keypoints = extract_keypoints(results)\n",
    "                npy_path = os.path.join(DATA_PATH, action, str(i), str(frame_num))\n",
    "                np.save(npy_path, keypoints)\n",
    "                #count = count+1\n",
    "    #                # 중간에 파일이 없어도 끊기지 않게\n",
    "    #                for i in range(0,sequence_length):\n",
    "    #                    if os.path.isfile('C:/Users/21SMT37/3차 프젝/MP_Data/3차/8/{}.npy'.format(i)):\n",
    "    #                        pass\n",
    "    #                    else : \n",
    "    #                        continue\n",
    "\n",
    "                # Break gracefully\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "#         cap.release()\n",
    "#         cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFont, ImageDraw, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'감사합니다': 0, '귀여워요': 1, '괜찮아요': 2, '미안합니다': 3, '기다려요': 4}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frame_num' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-4bc395d1a7bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mframe_num\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'frame_num' is not defined"
     ]
    }
   ],
   "source": [
    "frame_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "for action in actions :\n",
    "    for sequence in range(no_sequences):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence),\"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, SimpleRNN, Dropout, TimeDistributed, Conv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"Test!2\")\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 40, 258)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = Sequential()\n",
    "md.add(LSTM(128, return_sequences=True, activation='tanh', input_shape=(40,258)))\n",
    "md.add(LSTM(64, return_sequences=True, activation='tanh'))\n",
    "md.add(LSTM(32, return_sequences=False, activation='tanh'))\n",
    "md.add(Dense(64, activation='tanh'))\n",
    "md.add(Dense(32, activation='tanh'))\n",
    "md.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 40, 258), (80, 5))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adam(lr=0.0001)    #categorical_crossentropy : 이진 교차 엔트로피\n",
    "md.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy',\n",
    "           metrics=['categorical_accuracy']) # categorical_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.6481 - categorical_accuracy: 0.2000\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 1.6285 - categorical_accuracy: 0.2000\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6111 - categorical_accuracy: 0.2000\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5952 - categorical_accuracy: 0.2000\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5804 - categorical_accuracy: 0.2000\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5663 - categorical_accuracy: 0.2000\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5524 - categorical_accuracy: 0.2000\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5384 - categorical_accuracy: 0.2000\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5242 - categorical_accuracy: 0.5000\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5097 - categorical_accuracy: 0.6375\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4947 - categorical_accuracy: 0.6875\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.4796 - categorical_accuracy: 0.7250\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.4642 - categorical_accuracy: 0.7500\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4487 - categorical_accuracy: 0.7500\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4331 - categorical_accuracy: 0.7500\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4174 - categorical_accuracy: 0.7375\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4016 - categorical_accuracy: 0.7375\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.3856 - categorical_accuracy: 0.7250\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3696 - categorical_accuracy: 0.7250\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3533 - categorical_accuracy: 0.7250\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3369 - categorical_accuracy: 0.7375\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3202 - categorical_accuracy: 0.7375\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3032 - categorical_accuracy: 0.7375\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2856 - categorical_accuracy: 0.7625\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2675 - categorical_accuracy: 0.7750\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2491 - categorical_accuracy: 0.7750\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2305 - categorical_accuracy: 0.7750\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.2116 - categorical_accuracy: 0.7750\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1926 - categorical_accuracy: 0.7875\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1732 - categorical_accuracy: 0.7875\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1539 - categorical_accuracy: 0.7875\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1345 - categorical_accuracy: 0.8000\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1149 - categorical_accuracy: 0.8250\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.0952 - categorical_accuracy: 0.8250\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0753 - categorical_accuracy: 0.8375\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0553 - categorical_accuracy: 0.8500\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.0349 - categorical_accuracy: 0.8500\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.0142 - categorical_accuracy: 0.8625\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.9929 - categorical_accuracy: 0.8625\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.9712 - categorical_accuracy: 0.8625\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9491 - categorical_accuracy: 0.8750\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.9266 - categorical_accuracy: 0.8875\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9042 - categorical_accuracy: 0.9125\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8819 - categorical_accuracy: 0.9375\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.8597 - categorical_accuracy: 0.9250\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.8380 - categorical_accuracy: 0.9375\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8161 - categorical_accuracy: 0.9375\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7942 - categorical_accuracy: 0.9500\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7726 - categorical_accuracy: 0.9500\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7513 - categorical_accuracy: 0.9500\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7306 - categorical_accuracy: 0.9375\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7103 - categorical_accuracy: 0.9500\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6906 - categorical_accuracy: 0.9500\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6714 - categorical_accuracy: 0.9500\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6526 - categorical_accuracy: 0.9500\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6342 - categorical_accuracy: 0.9750\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6159 - categorical_accuracy: 0.9750\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5977 - categorical_accuracy: 0.9875\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5795 - categorical_accuracy: 0.9875\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5614 - categorical_accuracy: 0.9875\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5434 - categorical_accuracy: 0.9875\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5256 - categorical_accuracy: 1.0000\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5081 - categorical_accuracy: 1.0000\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4912 - categorical_accuracy: 1.0000\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4750 - categorical_accuracy: 1.0000\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4596 - categorical_accuracy: 1.0000\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4448 - categorical_accuracy: 1.0000\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4307 - categorical_accuracy: 1.0000\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4173 - categorical_accuracy: 1.0000\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4046 - categorical_accuracy: 1.0000\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3925 - categorical_accuracy: 1.0000\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3811 - categorical_accuracy: 1.0000\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3702 - categorical_accuracy: 1.0000\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3597 - categorical_accuracy: 1.0000\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3497 - categorical_accuracy: 1.0000\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3400 - categorical_accuracy: 1.0000\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3309 - categorical_accuracy: 1.0000\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3222 - categorical_accuracy: 1.0000\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3140 - categorical_accuracy: 1.0000\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3062 - categorical_accuracy: 1.0000\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2987 - categorical_accuracy: 1.0000\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2915 - categorical_accuracy: 1.0000\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2847 - categorical_accuracy: 1.0000\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2781 - categorical_accuracy: 1.0000\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2718 - categorical_accuracy: 1.0000\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2657 - categorical_accuracy: 1.0000\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2598 - categorical_accuracy: 1.0000\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2542 - categorical_accuracy: 1.0000\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2488 - categorical_accuracy: 1.0000\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2436 - categorical_accuracy: 1.0000\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2387 - categorical_accuracy: 1.0000\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2339 - categorical_accuracy: 1.0000\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2294 - categorical_accuracy: 1.0000\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2249 - categorical_accuracy: 1.0000\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2207 - categorical_accuracy: 1.0000\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2166 - categorical_accuracy: 1.0000\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2126 - categorical_accuracy: 1.0000\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2088 - categorical_accuracy: 1.0000\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2051 - categorical_accuracy: 1.0000\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2015 - categorical_accuracy: 1.0000\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1980 - categorical_accuracy: 1.0000\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1947 - categorical_accuracy: 1.0000\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1914 - categorical_accuracy: 1.0000\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1883 - categorical_accuracy: 1.0000\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1852 - categorical_accuracy: 1.0000\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.1823 - categorical_accuracy: 1.0000\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1794 - categorical_accuracy: 1.0000\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1767 - categorical_accuracy: 1.0000\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1740 - categorical_accuracy: 1.0000\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1714 - categorical_accuracy: 1.0000\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1688 - categorical_accuracy: 1.0000\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1664 - categorical_accuracy: 1.0000\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1640 - categorical_accuracy: 1.0000\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1616 - categorical_accuracy: 1.0000\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1594 - categorical_accuracy: 1.0000\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1572 - categorical_accuracy: 1.0000\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1550 - categorical_accuracy: 1.0000\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1529 - categorical_accuracy: 1.0000\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1509 - categorical_accuracy: 1.0000\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1489 - categorical_accuracy: 1.0000\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1470 - categorical_accuracy: 1.0000\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1451 - categorical_accuracy: 1.0000\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1433 - categorical_accuracy: 1.0000\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1415 - categorical_accuracy: 1.0000\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1397 - categorical_accuracy: 1.0000\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1380 - categorical_accuracy: 1.0000\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1364 - categorical_accuracy: 1.0000\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1347 - categorical_accuracy: 1.0000\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1332 - categorical_accuracy: 1.0000\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1316 - categorical_accuracy: 1.0000\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1301 - categorical_accuracy: 1.0000\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1286 - categorical_accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1271 - categorical_accuracy: 1.0000\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1257 - categorical_accuracy: 1.0000\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1243 - categorical_accuracy: 1.0000\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1229 - categorical_accuracy: 1.0000\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1216 - categorical_accuracy: 1.0000\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1203 - categorical_accuracy: 1.0000\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1190 - categorical_accuracy: 1.0000\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1177 - categorical_accuracy: 1.0000\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1165 - categorical_accuracy: 1.0000\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1153 - categorical_accuracy: 1.0000\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1141 - categorical_accuracy: 1.0000\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1130 - categorical_accuracy: 1.0000\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1118 - categorical_accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1107 - categorical_accuracy: 1.0000\n",
      "Epoch 147/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1096 - categorical_accuracy: 1.0000\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1085 - categorical_accuracy: 1.0000\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1075 - categorical_accuracy: 1.0000\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1064 - categorical_accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1054 - categorical_accuracy: 1.0000\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1044 - categorical_accuracy: 1.0000\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1034 - categorical_accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1024 - categorical_accuracy: 1.0000\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1015 - categorical_accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1005 - categorical_accuracy: 1.0000\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0996 - categorical_accuracy: 1.0000\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0987 - categorical_accuracy: 1.0000\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0978 - categorical_accuracy: 1.0000\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0969 - categorical_accuracy: 1.0000\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0961 - categorical_accuracy: 1.0000\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0952 - categorical_accuracy: 1.0000\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0944 - categorical_accuracy: 1.0000\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0936 - categorical_accuracy: 1.0000\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0928 - categorical_accuracy: 1.0000\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0920 - categorical_accuracy: 1.0000\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0912 - categorical_accuracy: 1.0000\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0904 - categorical_accuracy: 1.0000\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0896 - categorical_accuracy: 1.0000\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0889 - categorical_accuracy: 1.0000\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0882 - categorical_accuracy: 1.0000\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0874 - categorical_accuracy: 1.0000\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0867 - categorical_accuracy: 1.0000\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0860 - categorical_accuracy: 1.0000\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0853 - categorical_accuracy: 1.0000\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0846 - categorical_accuracy: 1.0000\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0840 - categorical_accuracy: 1.0000\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0833 - categorical_accuracy: 1.0000\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0826 - categorical_accuracy: 1.0000\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0820 - categorical_accuracy: 1.0000\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0814 - categorical_accuracy: 1.0000\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0807 - categorical_accuracy: 1.0000\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0801 - categorical_accuracy: 1.0000\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0795 - categorical_accuracy: 1.0000\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0789 - categorical_accuracy: 1.0000\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0783 - categorical_accuracy: 1.0000\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0777 - categorical_accuracy: 1.0000\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0771 - categorical_accuracy: 1.0000\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0766 - categorical_accuracy: 1.0000\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0760 - categorical_accuracy: 1.0000\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0754 - categorical_accuracy: 1.0000\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0749 - categorical_accuracy: 1.0000\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0743 - categorical_accuracy: 1.0000\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0738 - categorical_accuracy: 1.0000\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0733 - categorical_accuracy: 1.0000\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0728 - categorical_accuracy: 1.0000\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0722 - categorical_accuracy: 1.0000\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0717 - categorical_accuracy: 1.0000\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0712 - categorical_accuracy: 1.0000\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0707 - categorical_accuracy: 1.0000\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0702 - categorical_accuracy: 1.0000\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0698 - categorical_accuracy: 1.0000\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0693 - categorical_accuracy: 1.0000\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0688 - categorical_accuracy: 1.0000\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0683 - categorical_accuracy: 1.0000\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0679 - categorical_accuracy: 1.0000\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0674 - categorical_accuracy: 1.0000\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0670 - categorical_accuracy: 1.0000\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0665 - categorical_accuracy: 1.0000\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0661 - categorical_accuracy: 1.0000\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0656 - categorical_accuracy: 1.0000\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0652 - categorical_accuracy: 1.0000\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0648 - categorical_accuracy: 1.0000\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0644 - categorical_accuracy: 1.0000\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0640 - categorical_accuracy: 1.0000\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0635 - categorical_accuracy: 1.0000\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0631 - categorical_accuracy: 1.0000\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0627 - categorical_accuracy: 1.0000\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0623 - categorical_accuracy: 1.0000\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0620 - categorical_accuracy: 1.0000\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0616 - categorical_accuracy: 1.0000\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0612 - categorical_accuracy: 1.0000\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0608 - categorical_accuracy: 1.0000\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0604 - categorical_accuracy: 1.0000\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0601 - categorical_accuracy: 1.0000\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0597 - categorical_accuracy: 1.0000\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0593 - categorical_accuracy: 1.0000\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0590 - categorical_accuracy: 1.0000\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0586 - categorical_accuracy: 1.0000\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0583 - categorical_accuracy: 1.0000\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0579 - categorical_accuracy: 1.0000\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0576 - categorical_accuracy: 1.0000\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0572 - categorical_accuracy: 1.0000\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0569 - categorical_accuracy: 1.0000\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0566 - categorical_accuracy: 1.0000\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0562 - categorical_accuracy: 1.0000\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0559 - categorical_accuracy: 1.0000\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0556 - categorical_accuracy: 1.0000\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0553 - categorical_accuracy: 1.0000\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0549 - categorical_accuracy: 1.0000\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0546 - categorical_accuracy: 1.0000\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0543 - categorical_accuracy: 1.0000\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0540 - categorical_accuracy: 1.0000\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0537 - categorical_accuracy: 1.0000\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0534 - categorical_accuracy: 1.0000\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0531 - categorical_accuracy: 1.0000\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0528 - categorical_accuracy: 1.0000\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0525 - categorical_accuracy: 1.0000\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0522 - categorical_accuracy: 1.0000\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0520 - categorical_accuracy: 1.0000\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0517 - categorical_accuracy: 1.0000\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0514 - categorical_accuracy: 1.0000\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0511 - categorical_accuracy: 1.0000\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0508 - categorical_accuracy: 1.0000\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0506 - categorical_accuracy: 1.0000\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0503 - categorical_accuracy: 1.0000\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0500 - categorical_accuracy: 1.0000\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0498 - categorical_accuracy: 1.0000\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0495 - categorical_accuracy: 1.0000\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0492 - categorical_accuracy: 1.0000\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0490 - categorical_accuracy: 1.0000\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0487 - categorical_accuracy: 1.0000\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0485 - categorical_accuracy: 1.0000\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0482 - categorical_accuracy: 1.0000\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0480 - categorical_accuracy: 1.0000\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0477 - categorical_accuracy: 1.0000\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0475 - categorical_accuracy: 1.0000\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0472 - categorical_accuracy: 1.0000\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0470 - categorical_accuracy: 1.0000\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0468 - categorical_accuracy: 1.0000\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0465 - categorical_accuracy: 1.0000\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0463 - categorical_accuracy: 1.0000\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0461 - categorical_accuracy: 1.0000\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0458 - categorical_accuracy: 1.0000\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0456 - categorical_accuracy: 1.0000\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0454 - categorical_accuracy: 1.0000\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0452 - categorical_accuracy: 1.0000\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0449 - categorical_accuracy: 1.0000\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0447 - categorical_accuracy: 1.0000\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0445 - categorical_accuracy: 1.0000\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0443 - categorical_accuracy: 1.0000\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0441 - categorical_accuracy: 1.0000\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0439 - categorical_accuracy: 1.0000\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0436 - categorical_accuracy: 1.0000\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0434 - categorical_accuracy: 1.0000\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0432 - categorical_accuracy: 1.0000\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0430 - categorical_accuracy: 1.0000\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0428 - categorical_accuracy: 1.0000\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0426 - categorical_accuracy: 1.0000\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0424 - categorical_accuracy: 1.0000\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0422 - categorical_accuracy: 1.0000\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0420 - categorical_accuracy: 1.0000\n",
      "Epoch 293/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0418 - categorical_accuracy: 1.0000\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0416 - categorical_accuracy: 1.0000\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0414 - categorical_accuracy: 1.0000\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0413 - categorical_accuracy: 1.0000\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0411 - categorical_accuracy: 1.0000\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0409 - categorical_accuracy: 1.0000\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0407 - categorical_accuracy: 1.0000\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0405 - categorical_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "h = md.fit(X_train, y_train, batch_size=128,\n",
    "         epochs = 300, callbacks=[tb_callback]) # tensorboard_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 40, 128)           198144    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 40, 64)            49408     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 264,325\n",
      "Trainable params: 264,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "md.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.plot(range(1, 301, 1),\n",
    "         h.history['categorical_accuracy'],\n",
    "         label='categorical_accuracy'\n",
    "         )\n",
    "\n",
    "plt.plot(range(1, 301, 1),\n",
    "         h.history['loss'],\n",
    "         label='loss'\n",
    "         )\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = md.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'괜찮아요'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res[8])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'감사합니다'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(y_test[8])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.save('Test1.h5')  # 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.load_weights('Test1.h5')  # 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix,accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = md.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = np.argmax(y_train, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[64,  0],\n",
       "        [ 0, 16]],\n",
       "\n",
       "       [[62,  1],\n",
       "        [ 0, 17]],\n",
       "\n",
       "       [[62,  0],\n",
       "        [ 3, 15]],\n",
       "\n",
       "       [[65,  1],\n",
       "        [ 0, 14]],\n",
       "\n",
       "       [[63,  2],\n",
       "        [ 1, 14]]], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-e74e225ecbf3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1340\u001b[0m     \u001b[0mbase_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_api_gauge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'evaluate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1341\u001b[0m     \u001b[0mversion_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'evaluate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1342\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1343\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'evaluate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1344\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'evaluate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2590\u001b[0m     \u001b[1;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2591\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2592\u001b[1;33m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[0;32m   2593\u001b[0m                          \u001b[1;34m'training/testing. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2594\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "md.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(245,117,16),(117,245,16),(16,117,245),(245,117,16),(117,245,16)]\n",
    "# ,(245,117,16),(117,245,16),(16,117,245),(245,117,16)\n",
    "#          ,(117,245,16),(16,117,245),(245,117,16),(117,245,16),(16,117,245)\n",
    "def prob_viz(res,actions,input_frame,colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame, (0,60+num*40),(int(prob*100),90+num*40),colors[num],-1)\n",
    "        cv2.putText(output_frame, actions[num],(0,85+num*40),cv2.FONT_HERSHEY_SIMPLEX,1,\n",
    "                    (255,255,255),2,cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -*- coding : utf-8 -*-\n",
    "# import sys\n",
    "# print(sys.getdefaultencoding())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-e9fc5980c1bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m800\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;31m#print(\"비디오 읽기 실패 / 비디오 모두 읽음\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imutils\\convenience.py\u001b[0m in \u001b[0;36mresize\u001b[1;34m(image, width, height, inter)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;31m# grab the image size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;31m# if both the width and height are None, then return the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# -*- coding : utf-8 -*-\n",
    "import cv2\n",
    "from PIL import ImageFont, ImageDraw, Image  # 한글 출력 임포트\n",
    "# 1. New detection variables\n",
    "sequence = []\n",
    "sentence = []\n",
    "threshold = 0.7\n",
    "predictions = []\n",
    "\n",
    "def most_frequent(data):\n",
    "    return max(data, key=data.count)\n",
    "cnt = 0\n",
    "result_actions = 0\n",
    "\n",
    "word=['감사합니다','귀여워요','괜찮아요','미안합니다','기다려요']\n",
    "b,g,r,a = 0,0,0,10\n",
    "fontpath = \"fonts/gulim.ttc\"\n",
    "font = ImageFont.truetype(fontpath, 40)\n",
    "\n",
    "cap = cv2.VideoCapture(\"./img/A1.mp4\")\n",
    "#cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:   \n",
    "    while cap.isOpened():\n",
    "    \n",
    "        # read feed\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        frame = imutils.resize(frame, width=800)\n",
    "        if not ret:\n",
    "            #print(\"비디오 읽기 실패 / 비디오 모두 읽음\")\n",
    "            print(\"Finish\")\n",
    "            cap.release()   # 비디오 읽기 종료\n",
    "            cv2.destroyAllWindows()  # 새로 연 창을 모두 닫아줌\n",
    "            break\n",
    "            \n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame,holistic)\n",
    "#         print(results)\n",
    "        \n",
    "#         image = Image.fromarray(image)\n",
    "#         draw = ImageDraw.Draw(image)\n",
    "#         draw.text(xy=(10,15), text=actions[np.argmax(res)], font=font, fill=(255,255,255))\n",
    "#         image=np.array(image)\n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "        \n",
    "        img_pil = Image.fromarray(image)\n",
    "        draw = ImageDraw.Draw(img_pil)\n",
    "        \n",
    "        #2. Prediction logic\n",
    "        keypoints = extract_keypoints(results)\n",
    "#        sequence.insert(0,keypoints)\n",
    "#        sequence = sequence[:30]\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-40:]\n",
    "        \n",
    "        label = actions[np.argmax(res)]\n",
    "        if len(sequence) == 40 :  # 30 프레임 \n",
    "                 #np.expand_dims : (s_num,50,1662)을 캡슐화\n",
    "            res = md.predict(np.expand_dims(sequence, axis=0))[0]            \n",
    "#            print(actions[np.argmax(res)])\n",
    "#            predictions.append(np.argmax(res))\n",
    "        \n",
    "# # # #         # 3. Viz logic\n",
    "#         if np.unique(predictions[:10]) ==np.argmax(res): \n",
    "        \n",
    "        if res[np.argmax(res)] > threshold: # 정확도                \n",
    "            if len(sentence) > 0:\n",
    "                if actions[np.argmax(res)] != sentence[-1]:\n",
    "                    sentence.append(actions[np.argmax(res)])\n",
    "#                     print(actions[np.argmax(res)])\n",
    "            else :                               \n",
    "                sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "#         if len(sentence) > 2 : #화면출력 글자 수\n",
    "#             sentence = sentence[-2:]\n",
    "#                 #draw.text(xy=(10,15), text=sentence, font=font, fill=(255,255,255))\n",
    "#     #         # VIz probabilities\n",
    "# #        image = prob_viz(res, actions, image, colors)\n",
    "#     #         draw.text(xy=(10,15), text=actions[np.argmax(res)], font=font, fill=(255,255,255))  \n",
    "#         cv2.rectangle(image, (0,0), (640,40), (245, 117, 16), -1)\n",
    "#         cv2.putText(image, ' '.join(sentence), (3,30),\n",
    "#                     cv2.FONT_HERSHEY_SIMPLEX,1, (255,255,255), 2, cv2.LINE_AA)\n",
    "#         if result_actions == label:            \n",
    "#             cnt += 1\n",
    "# #         elif result_actions != label:\n",
    "# #             cnt = 0\n",
    "        \n",
    "#         result_actions = \"귀여워요\"\n",
    "#         if cnt >= 15:\n",
    "#             #print(result_actions)\n",
    "            draw.text((10, 10), actions[np.argmax(res)] , font=font, fill=(b,g,r,a))\n",
    "            image = np.array(img_pil)\n",
    "            \n",
    "        \n",
    "        # show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "        \n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) == 27:\n",
    "            break\n",
    "            \n",
    "        \n",
    "    #print(actions[np.argmax(res)])\n",
    "#     def most_frequent(data):\n",
    "#         count_list=[]\n",
    "\n",
    "#         for x in data: \n",
    "#             count_list.append(data.count(x))\n",
    " \n",
    "#         return data[count_list.index(max(count_list))]\n",
    "\n",
    "#     print(most_frequent(sequence))\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(most_frequent(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions[np.argmax(res)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.predict(np.expand_dims(sequence, axis=0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(sequence, axis=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
