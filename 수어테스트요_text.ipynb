{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.4.1 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (2.4.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.2; however, version 21.2.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\21smt17\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: tensorflow-gpu==2.4.1 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (4.5.3.56)\n",
      "Requirement already satisfied: mediapipe in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (0.8.6.2)\n",
      "Requirement already satisfied: sklearn in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (1.32.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (3.7.4.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (2.4.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (3.17.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (3.3.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (2.10.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (1.12.1)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (1.1.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (0.35.1)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (1.15.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (2.5.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (1.12)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (1.1.2)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (1.19.2)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (0.3.3)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (0.13.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (1.6.3)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from mediapipe) (20.3.0)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from mediapipe) (4.5.3.56)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from matplotlib) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from matplotlib) (8.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.24.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (50.3.1.post20201107)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.34.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.25.11)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.1.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.17.0)\n",
      "Requirement already satisfied: imutils in c:\\users\\21smt17\\anaconda3\\lib\\site-packages (0.5.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.2; however, version 21.2.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\21smt17\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 opencv-python mediapipe sklearn matplotlib\n",
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding:utf-8-*-\n",
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic #Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                   # Image is no longer writeable\n",
    "    results = model.process(image)                  # Make prediction\n",
    "    image.flags.writeable = True                    # Image is now writeable\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # COLOR CONVERSION RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS) # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({(<PoseLandmark.NOSE: 0>, <PoseLandmark.LEFT_EYE_INNER: 1>),\n",
       "           (<PoseLandmark.NOSE: 0>, <PoseLandmark.RIGHT_EYE_INNER: 4>),\n",
       "           (<PoseLandmark.LEFT_EYE_INNER: 1>, <PoseLandmark.LEFT_EYE: 2>),\n",
       "           (<PoseLandmark.LEFT_EYE: 2>, <PoseLandmark.LEFT_EYE_OUTER: 3>),\n",
       "           (<PoseLandmark.LEFT_EYE_OUTER: 3>, <PoseLandmark.LEFT_EAR: 7>),\n",
       "           (<PoseLandmark.RIGHT_EYE_INNER: 4>, <PoseLandmark.RIGHT_EYE: 5>),\n",
       "           (<PoseLandmark.RIGHT_EYE: 5>, <PoseLandmark.RIGHT_EYE_OUTER: 6>),\n",
       "           (<PoseLandmark.RIGHT_EYE_OUTER: 6>, <PoseLandmark.RIGHT_EAR: 8>),\n",
       "           (<PoseLandmark.MOUTH_RIGHT: 10>, <PoseLandmark.MOUTH_LEFT: 9>),\n",
       "           (<PoseLandmark.LEFT_SHOULDER: 11>, <PoseLandmark.LEFT_ELBOW: 13>),\n",
       "           (<PoseLandmark.LEFT_SHOULDER: 11>, <PoseLandmark.LEFT_HIP: 23>),\n",
       "           (<PoseLandmark.RIGHT_SHOULDER: 12>,\n",
       "            <PoseLandmark.LEFT_SHOULDER: 11>),\n",
       "           (<PoseLandmark.RIGHT_SHOULDER: 12>, <PoseLandmark.RIGHT_ELBOW: 14>),\n",
       "           (<PoseLandmark.RIGHT_SHOULDER: 12>, <PoseLandmark.RIGHT_HIP: 24>),\n",
       "           (<PoseLandmark.LEFT_ELBOW: 13>, <PoseLandmark.LEFT_WRIST: 15>),\n",
       "           (<PoseLandmark.RIGHT_ELBOW: 14>, <PoseLandmark.RIGHT_WRIST: 16>),\n",
       "           (<PoseLandmark.LEFT_WRIST: 15>, <PoseLandmark.LEFT_PINKY: 17>),\n",
       "           (<PoseLandmark.LEFT_WRIST: 15>, <PoseLandmark.LEFT_INDEX: 19>),\n",
       "           (<PoseLandmark.LEFT_WRIST: 15>, <PoseLandmark.LEFT_THUMB: 21>),\n",
       "           (<PoseLandmark.RIGHT_WRIST: 16>, <PoseLandmark.RIGHT_PINKY: 18>),\n",
       "           (<PoseLandmark.RIGHT_WRIST: 16>, <PoseLandmark.RIGHT_INDEX: 20>),\n",
       "           (<PoseLandmark.RIGHT_WRIST: 16>, <PoseLandmark.RIGHT_THUMB: 22>),\n",
       "           (<PoseLandmark.LEFT_PINKY: 17>, <PoseLandmark.LEFT_INDEX: 19>),\n",
       "           (<PoseLandmark.RIGHT_PINKY: 18>, <PoseLandmark.RIGHT_INDEX: 20>),\n",
       "           (<PoseLandmark.LEFT_HIP: 23>, <PoseLandmark.LEFT_KNEE: 25>),\n",
       "           (<PoseLandmark.RIGHT_HIP: 24>, <PoseLandmark.LEFT_HIP: 23>),\n",
       "           (<PoseLandmark.RIGHT_HIP: 24>, <PoseLandmark.RIGHT_KNEE: 26>),\n",
       "           (<PoseLandmark.LEFT_KNEE: 25>, <PoseLandmark.LEFT_ANKLE: 27>),\n",
       "           (<PoseLandmark.RIGHT_KNEE: 26>, <PoseLandmark.RIGHT_ANKLE: 28>),\n",
       "           (<PoseLandmark.LEFT_ANKLE: 27>, <PoseLandmark.LEFT_HEEL: 29>),\n",
       "           (<PoseLandmark.LEFT_ANKLE: 27>, <PoseLandmark.LEFT_FOOT_INDEX: 31>),\n",
       "           (<PoseLandmark.RIGHT_ANKLE: 28>, <PoseLandmark.RIGHT_HEEL: 30>),\n",
       "           (<PoseLandmark.RIGHT_ANKLE: 28>,\n",
       "            <PoseLandmark.RIGHT_FOOT_INDEX: 32>),\n",
       "           (<PoseLandmark.LEFT_HEEL: 29>, <PoseLandmark.LEFT_FOOT_INDEX: 31>),\n",
       "           (<PoseLandmark.RIGHT_HEEL: 30>,\n",
       "            <PoseLandmark.RIGHT_FOOT_INDEX: 32>)})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_holistic.POSE_CONNECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "#     mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS,\n",
    "#                              mp_drawing.DrawingSpec(color=(80,110,10), thickness=1,circle_radius=1),\n",
    "#                              mp_drawing.DrawingSpec(color=(80,265,121), thickness=1,circle_radius=1)\n",
    "#                              ) # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2,circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2,circle_radius=2)) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2,circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2,circle_radius=2)) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(245,117,6), thickness=2,circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2,circle_radius=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "#cap = cv2.VideoCapture(0)\n",
    "# for i in range(0,3):\n",
    "#cap = cv2.VideoCapture(\"./img/NIA_SL_WORD2751_REAL01_F.mp4\")\n",
    "#cap = cv2.VideoCapture(\"./img/T1.mp4\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "# for i in range(0,2,1):\n",
    "#     cap = cv2.VideoCapture(\"./img/KETI_SL_000000000\"+\"{}.avi\".format(i + 2))\n",
    "    \n",
    "# Set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        \n",
    "    \n",
    "        # Read feed        \n",
    "        ret, frame = cap.read()\n",
    "        #frame = imutils.resize(frame, width=1200)\n",
    "#         if not ret:\n",
    "#             print(\"비디오 읽기 실패 / 비디오 모두 읽음\")\n",
    "#             cap.release()   # 비디오 읽기 종료\n",
    "#             cv2.destroyAllWindows()  # 새로 연 창을 모두 닫아줌\n",
    "#             break\n",
    "        # Make detections(탐지들)\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        print(results)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "        \n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "        \n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results.left_hand_landmarks.landmark\n",
    "len(results.right_hand_landmarks.landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(draw_landmarks(frame, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = []\n",
    "for res in results.pose_landmarks.landmark:\n",
    "    test = np.array([res.x, res.y, res.z, res.visibility])\n",
    "    pose.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "#pose\n",
    "#len(pose)\n",
    "#pose = np.array([[res.x, res.y, res.z, res.visibility(저항)] for res in results.pose_landmarks.landmark])\n",
    "pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)\n",
    "face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(1404)                                                                                                   # 학습시킬려고 flatten으로 쫙 펴줌\n",
    "lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "   pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "#    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)                                                                                                   # 학습시킬려고 flatten으로 쫙 펴줌\n",
    "   lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "   rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3) \n",
    "   return np.concatenate([pose, lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(results.face_landmarks.landmark) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.72553742e-01,  4.82764006e-01, -5.18416891e-05,  7.22261369e-01,\n",
       "        4.71668482e-01, -2.42888685e-02,  6.83698654e-01,  4.30453897e-01,\n",
       "       -3.32258046e-02,  6.62606776e-01,  3.88677537e-01, -4.38125096e-02,\n",
       "        6.48631215e-01,  3.59552532e-01, -5.37799485e-02,  7.14212179e-01,\n",
       "        3.41192454e-01,  4.95578302e-03,  6.91749156e-01,  2.91468412e-01,\n",
       "       -4.16507619e-03,  6.79816961e-01,  2.58509070e-01, -1.63817033e-02,\n",
       "        6.71166539e-01,  2.29815394e-01, -2.48669069e-02,  7.43252695e-01,\n",
       "        3.25180799e-01,  5.40196802e-03,  7.31994629e-01,  2.62478322e-01,\n",
       "        7.40574952e-03,  7.26909876e-01,  2.21591830e-01, -6.11211499e-03,\n",
       "        7.23818660e-01,  1.84903726e-01, -1.69169046e-02,  7.70717919e-01,\n",
       "        3.24362069e-01,  1.18217315e-03,  7.68752098e-01,  2.63562351e-01,\n",
       "       -1.65251875e-03,  7.67558694e-01,  2.23051041e-01, -1.44589227e-02,\n",
       "        7.66027749e-01,  1.87587023e-01, -2.57512853e-02,  7.97989786e-01,\n",
       "        3.36130917e-01, -7.83585571e-03,  8.08770239e-01,  2.87480593e-01,\n",
       "       -1.50246210e-02,  8.15421820e-01,  2.56077498e-01, -2.49114651e-02,\n",
       "        8.20693672e-01,  2.26683527e-01, -3.34009491e-02])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.67484421e-01,  4.72166061e-01, -1.94571148e-05,  4.13737595e-01,\n",
       "        4.50693309e-01, -8.22601654e-03,  4.47822452e-01,  3.99460077e-01,\n",
       "       -5.55050652e-03,  4.66614157e-01,  3.56212050e-01, -6.19359268e-03,\n",
       "        4.82483238e-01,  3.31261784e-01, -7.52679398e-03,  4.12096977e-01,\n",
       "        3.15232456e-01,  1.49688683e-02,  4.30908084e-01,  2.60299921e-01,\n",
       "        9.29309521e-03,  4.41559225e-01,  2.26733774e-01,  3.24125448e-03,\n",
       "        4.49822634e-01,  1.96389392e-01, -2.32772343e-03,  3.83237064e-01,\n",
       "        3.02313894e-01,  8.09591357e-03,  3.87370020e-01,  2.36551434e-01,\n",
       "        3.75996530e-03,  3.90258610e-01,  1.96011901e-01, -5.61167533e-03,\n",
       "        3.92127961e-01,  1.63129315e-01, -1.13428235e-02,  3.56078297e-01,\n",
       "        3.04522693e-01, -2.70230928e-03,  3.53256971e-01,  2.42216915e-01,\n",
       "       -1.15499655e-02,  3.53890449e-01,  2.02621818e-01, -2.23084502e-02,\n",
       "        3.55256081e-01,  1.69425488e-01, -2.99432147e-02,  3.29741597e-01,\n",
       "        3.22026998e-01, -1.51789915e-02,  3.11949432e-01,  2.79214621e-01,\n",
       "       -2.55571399e-02,  3.01155955e-01,  2.49485508e-01, -3.54940183e-02,\n",
       "        2.91935444e-01,  2.20385194e-01, -4.34340462e-02])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(21*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract_keypoints(results).shape\n",
    "result_test = extract_keypoints(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.48791289e-01,  3.16651255e-01, -4.43807065e-01,  9.99502659e-01,\n",
       "        5.71273685e-01,  2.53497243e-01, -4.18215364e-01,  9.99396265e-01,\n",
       "        5.90462446e-01,  2.51938760e-01, -4.17661518e-01,  9.99227226e-01,\n",
       "        6.09732211e-01,  2.53888577e-01, -4.17885453e-01,  9.99389768e-01,\n",
       "        5.21912932e-01,  2.67842472e-01, -3.86885345e-01,  9.99280095e-01,\n",
       "        5.08461833e-01,  2.73829401e-01, -3.87976229e-01,  9.99040186e-01,\n",
       "        4.92022514e-01,  2.77240187e-01, -3.88287097e-01,  9.99212384e-01,\n",
       "        6.26518250e-01,  2.86040336e-01, -1.64065316e-01,  9.99394596e-01,\n",
       "        4.78948981e-01,  3.10236365e-01, -5.27457409e-02,  9.99365151e-01,\n",
       "        5.92750251e-01,  3.86069953e-01, -3.55019659e-01,  9.99292254e-01,\n",
       "        5.16966164e-01,  3.93580437e-01, -3.15013528e-01,  9.99249935e-01,\n",
       "        7.59184599e-01,  5.51140726e-01, -9.42915529e-02,  9.97097313e-01,\n",
       "        4.20241922e-01,  5.81682742e-01,  1.21898398e-01,  9.95751560e-01,\n",
       "        9.19763923e-01,  9.02253509e-01, -7.13219523e-01,  8.74053001e-01,\n",
       "        2.79696405e-01,  8.58744264e-01, -3.79293978e-01,  8.85187030e-01,\n",
       "        7.81255364e-01,  5.00190079e-01, -1.17714655e+00,  9.91019309e-01,\n",
       "        3.79517615e-01,  4.69199032e-01, -9.63825583e-01,  9.86561537e-01,\n",
       "        7.63557851e-01,  3.71776044e-01, -1.25524676e+00,  9.85595167e-01,\n",
       "        3.89915645e-01,  3.59663486e-01, -1.06226385e+00,  9.77911592e-01,\n",
       "        7.46168315e-01,  3.43892872e-01, -1.10810959e+00,  9.84587967e-01,\n",
       "        4.15382385e-01,  3.40490520e-01, -9.43376184e-01,  9.76156414e-01,\n",
       "        7.29151905e-01,  3.98567110e-01, -1.12223101e+00,  9.79923785e-01,\n",
       "        4.25389469e-01,  3.85191530e-01, -9.42013443e-01,  9.69455838e-01,\n",
       "        6.89070344e-01,  1.28724349e+00, -1.35390908e-01,  2.90451255e-02,\n",
       "        4.81101662e-01,  1.26867831e+00,  1.37536466e-01,  3.63906324e-02,\n",
       "        6.49939418e-01,  1.81658340e+00, -1.25403076e-01,  1.90647803e-02,\n",
       "        4.37217951e-01,  1.82245421e+00,  9.54533666e-02,  1.05367824e-02,\n",
       "        6.72411084e-01,  2.31670046e+00,  3.91661704e-01,  3.26587353e-03,\n",
       "        4.64628220e-01,  2.35292077e+00,  2.92612016e-01,  1.70447608e-03,\n",
       "        6.84518933e-01,  2.40363455e+00,  4.45901722e-01,  4.14964743e-03,\n",
       "        4.78880346e-01,  2.44061613e+00,  3.06101024e-01,  1.62544358e-03,\n",
       "        6.23861849e-01,  2.44385219e+00,  2.25884750e-01,  7.48580042e-03,\n",
       "        4.44961399e-01,  2.48507643e+00, -5.21381907e-02,  4.25076578e-03,\n",
       "        7.72553742e-01,  4.82764006e-01, -5.18416891e-05,  7.22261369e-01,\n",
       "        4.71668482e-01, -2.42888685e-02,  6.83698654e-01,  4.30453897e-01,\n",
       "       -3.32258046e-02,  6.62606776e-01,  3.88677537e-01, -4.38125096e-02,\n",
       "        6.48631215e-01,  3.59552532e-01, -5.37799485e-02,  7.14212179e-01,\n",
       "        3.41192454e-01,  4.95578302e-03,  6.91749156e-01,  2.91468412e-01,\n",
       "       -4.16507619e-03,  6.79816961e-01,  2.58509070e-01, -1.63817033e-02,\n",
       "        6.71166539e-01,  2.29815394e-01, -2.48669069e-02,  7.43252695e-01,\n",
       "        3.25180799e-01,  5.40196802e-03,  7.31994629e-01,  2.62478322e-01,\n",
       "        7.40574952e-03,  7.26909876e-01,  2.21591830e-01, -6.11211499e-03,\n",
       "        7.23818660e-01,  1.84903726e-01, -1.69169046e-02,  7.70717919e-01,\n",
       "        3.24362069e-01,  1.18217315e-03,  7.68752098e-01,  2.63562351e-01,\n",
       "       -1.65251875e-03,  7.67558694e-01,  2.23051041e-01, -1.44589227e-02,\n",
       "        7.66027749e-01,  1.87587023e-01, -2.57512853e-02,  7.97989786e-01,\n",
       "        3.36130917e-01, -7.83585571e-03,  8.08770239e-01,  2.87480593e-01,\n",
       "       -1.50246210e-02,  8.15421820e-01,  2.56077498e-01, -2.49114651e-02,\n",
       "        8.20693672e-01,  2.26683527e-01, -3.34009491e-02,  3.67484421e-01,\n",
       "        4.72166061e-01, -1.94571148e-05,  4.13737595e-01,  4.50693309e-01,\n",
       "       -8.22601654e-03,  4.47822452e-01,  3.99460077e-01, -5.55050652e-03,\n",
       "        4.66614157e-01,  3.56212050e-01, -6.19359268e-03,  4.82483238e-01,\n",
       "        3.31261784e-01, -7.52679398e-03,  4.12096977e-01,  3.15232456e-01,\n",
       "        1.49688683e-02,  4.30908084e-01,  2.60299921e-01,  9.29309521e-03,\n",
       "        4.41559225e-01,  2.26733774e-01,  3.24125448e-03,  4.49822634e-01,\n",
       "        1.96389392e-01, -2.32772343e-03,  3.83237064e-01,  3.02313894e-01,\n",
       "        8.09591357e-03,  3.87370020e-01,  2.36551434e-01,  3.75996530e-03,\n",
       "        3.90258610e-01,  1.96011901e-01, -5.61167533e-03,  3.92127961e-01,\n",
       "        1.63129315e-01, -1.13428235e-02,  3.56078297e-01,  3.04522693e-01,\n",
       "       -2.70230928e-03,  3.53256971e-01,  2.42216915e-01, -1.15499655e-02,\n",
       "        3.53890449e-01,  2.02621818e-01, -2.23084502e-02,  3.55256081e-01,\n",
       "        1.69425488e-01, -2.99432147e-02,  3.29741597e-01,  3.22026998e-01,\n",
       "       -1.51789915e-02,  3.11949432e-01,  2.79214621e-01, -2.55571399e-02,\n",
       "        3.01155955e-01,  2.49485508e-01, -3.54940183e-02,  2.91935444e-01,\n",
       "        2.20385194e-01, -4.34340462e-02])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1662"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "468*3+33*4+21*3+21*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 파일에 0.npy 파일 생김   test용\n",
    "np.save('0', result_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('HandSign_text')\n",
    "\n",
    "# Actions that we try to detect\n",
    "#actions = np.array(['coco','love','HM'])\n",
    "#actions = np.array(['T1','T2','T3','T4','T5','T6','T7','T8','T9','T10','T11','T12'])\n",
    "#actions = np.array(['감사합니다','귀여워요','괜찮아요','미안합니다','기다려요'])\n",
    "actions = np.array(['함께 식사할까요','안녕하세요 만나서 반갑습니다','잘 지냈어요','오랜만이야','네 알고있습니다',\n",
    "                    '감사합니다','귀여워요','괜찮아요','미안합니다','즐겁다','평화','화장실','여기','병원','배고프다'])\n",
    "# Thirty videos worth of data\n",
    "no_sequences =  20#60#10      #29 , 16, 5\n",
    "\n",
    "# videos are going to be 30 frames in length\n",
    "sequence_length = 50#40#50    #30, 20, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더 세개 생성!! 딥러닝 -> 안녕, 나는, 아가형민 순서대로 생김\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        try:\n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "        except :\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)    \n",
    "    # Set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "#     for action in actions:        \n",
    "    # New Loop\n",
    "    # Loop through actions\n",
    "        \n",
    "\n",
    "        # Loop through sequences aka videos\n",
    "\n",
    "#    for action in actions:\n",
    "        for i in range(0,20,1):        \n",
    "            for frame_num in range(sequence_length):                \n",
    "\n",
    "                # read feed\n",
    "                ret, frame = cap.read()\n",
    "                #frame = imutils.resize(frame, width=800)\n",
    "                # Make detections\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "    #                print(results)\n",
    "\n",
    "                # Draw landmarks\n",
    "                draw_styled_landmarks(image, results)\n",
    "\n",
    "                # New Apply wait logic\n",
    "                if frame_num == 0:\n",
    "                    cv2.putText(image, 'STRATING COLLECTION', (120,200),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 4, cv2.LINE_AA)\n",
    "                    cv2.putText(image, 'Collecting frames for {} Video Number{} f_num{}'.format('네 알고있습니다', i,frame_num), (15,12),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1, cv2.LINE_AA)\n",
    "                        # show to screen\n",
    "\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                    cv2.waitKey(2000) # 1000\n",
    "\n",
    "                else : \n",
    "                    cv2.putText(image, 'Collecting frames for {} Video Number{} f_num{}'.format('네 알고있습니다', i, frame_num), (15,12),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1, cv2.LINE_AA)\n",
    "                        # show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "                # NEW Export keypoints\n",
    "                keypoints = extract_keypoints(results)\n",
    "                npy_path = os.path.join(DATA_PATH, '네 알고있습니다', str(i), str(frame_num))\n",
    "                np.save(npy_path, keypoints)\n",
    "                #count = count+1\n",
    "    #                # 중간에 파일이 없어도 끊기지 않게\n",
    "    #                for i in range(0,sequence_length):\n",
    "    #                    if os.path.isfile('C:/Users/21SMT37/3차 프젝/MP_Data/3차/8/{}.npy'.format(i)):\n",
    "    #                        pass\n",
    "    #                    else : \n",
    "    #                        continue\n",
    "\n",
    "                # Break gracefully\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "#         cap.release()\n",
    "#         cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFont, ImageDraw, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'함께 식사할까요': 0,\n",
       " '안녕하세요 만나서 반갑습니다': 1,\n",
       " '잘 지냈어요': 2,\n",
       " '오랜만이야': 3,\n",
       " '네 알고있습니다': 4,\n",
       " '감사합니다': 5,\n",
       " '귀여워요': 6,\n",
       " '괜찮아요': 7,\n",
       " '미안합니다': 8,\n",
       " '즐겁다': 9,\n",
       " '평화': 10,\n",
       " '화장실': 11,\n",
       " '여기': 12,\n",
       " '병원': 13,\n",
       " '배고프다': 14}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "for action in actions :\n",
    "    for sequence in range(no_sequences):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence),\"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, SimpleRNN, Dropout, TimeDistributed, Conv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"Hand_plustext\")\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 50, 258)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = Sequential()\n",
    "md.add(LSTM(128, return_sequences=True, activation='tanh', input_shape=(50,258)))\n",
    "md.add(LSTM(64, return_sequences=True, activation='tanh'))\n",
    "md.add(LSTM(32, return_sequences=False, activation='tanh'))\n",
    "md.add(Dense(64, activation='tanh'))\n",
    "md.add(Dense(32, activation='tanh'))\n",
    "md.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((240, 50, 258), (240, 15))"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adam(lr=0.0001)    #categorical_crossentropy : 이진 교차 엔트로피\n",
    "md.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy',\n",
    "           metrics=['categorical_accuracy']) # categorical_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "2/2 [==============================] - 3s 652ms/step - loss: 2.7374 - categorical_accuracy: 0.0651\n",
      "Epoch 2/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 2.7102 - categorical_accuracy: 0.0573\n",
      "Epoch 3/400\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 2.6913 - categorical_accuracy: 0.1113\n",
      "Epoch 4/400\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 2.6704 - categorical_accuracy: 0.1245\n",
      "Epoch 5/400\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 2.6583 - categorical_accuracy: 0.2014\n",
      "Epoch 6/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 2.6425 - categorical_accuracy: 0.2099\n",
      "Epoch 7/400\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 2.6200 - categorical_accuracy: 0.2413\n",
      "Epoch 8/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 2.6005 - categorical_accuracy: 0.2174\n",
      "Epoch 9/400\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 2.5877 - categorical_accuracy: 0.2047\n",
      "Epoch 10/400\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 2.5622 - categorical_accuracy: 0.2392\n",
      "Epoch 11/400\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 2.5406 - categorical_accuracy: 0.2344\n",
      "Epoch 12/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 2.5071 - categorical_accuracy: 0.2663\n",
      "Epoch 13/400\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 2.4835 - categorical_accuracy: 0.2611\n",
      "Epoch 14/400\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 2.4544 - categorical_accuracy: 0.2722\n",
      "Epoch 15/400\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 2.4228 - categorical_accuracy: 0.3665\n",
      "Epoch 16/400\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 2.3941 - categorical_accuracy: 0.3839\n",
      "Epoch 17/400\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 2.3549 - categorical_accuracy: 0.4181\n",
      "Epoch 18/400\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 2.3286 - categorical_accuracy: 0.4024\n",
      "Epoch 19/400\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 2.2881 - categorical_accuracy: 0.4238\n",
      "Epoch 20/400\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 2.2568 - categorical_accuracy: 0.4408\n",
      "Epoch 21/400\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 2.2217 - categorical_accuracy: 0.4707\n",
      "Epoch 22/400\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 2.1877 - categorical_accuracy: 0.4865\n",
      "Epoch 23/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 2.1385 - categorical_accuracy: 0.5097\n",
      "Epoch 24/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 2.1135 - categorical_accuracy: 0.4868\n",
      "Epoch 25/400\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 2.0707 - categorical_accuracy: 0.5056\n",
      "Epoch 26/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 2.0348 - categorical_accuracy: 0.5137\n",
      "Epoch 27/400\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 1.9973 - categorical_accuracy: 0.5384\n",
      "Epoch 28/400\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 1.9742 - categorical_accuracy: 0.5734\n",
      "Epoch 29/400\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 1.9348 - categorical_accuracy: 0.5601\n",
      "Epoch 30/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 1.8937 - categorical_accuracy: 0.5870\n",
      "Epoch 31/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 1.8553 - categorical_accuracy: 0.6248\n",
      "Epoch 32/400\n",
      "2/2 [==============================] - 0s 169ms/step - loss: 1.8270 - categorical_accuracy: 0.6439\n",
      "Epoch 33/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 1.7908 - categorical_accuracy: 0.6740\n",
      "Epoch 34/400\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 1.7442 - categorical_accuracy: 0.7304\n",
      "Epoch 35/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 1.7398 - categorical_accuracy: 0.7288\n",
      "Epoch 36/400\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 1.6874 - categorical_accuracy: 0.7557\n",
      "Epoch 37/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 1.6649 - categorical_accuracy: 0.7885\n",
      "Epoch 38/400\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 1.6334 - categorical_accuracy: 0.8128\n",
      "Epoch 39/400\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 1.5924 - categorical_accuracy: 0.8800\n",
      "Epoch 40/400\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 1.5761 - categorical_accuracy: 0.8642\n",
      "Epoch 41/400\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 1.5331 - categorical_accuracy: 0.8535\n",
      "Epoch 42/400\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 1.5017 - categorical_accuracy: 0.8752\n",
      "Epoch 43/400\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 1.4726 - categorical_accuracy: 0.8861\n",
      "Epoch 44/400\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 1.4499 - categorical_accuracy: 0.9073\n",
      "Epoch 45/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 1.4193 - categorical_accuracy: 0.8937\n",
      "Epoch 46/400\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 1.3803 - categorical_accuracy: 0.8915\n",
      "Epoch 47/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 1.3529 - categorical_accuracy: 0.9368\n",
      "Epoch 48/400\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 1.3433 - categorical_accuracy: 0.9106\n",
      "Epoch 49/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 1.3115 - categorical_accuracy: 0.9405\n",
      "Epoch 50/400\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 1.2769 - categorical_accuracy: 0.9510\n",
      "Epoch 51/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 1.2546 - categorical_accuracy: 0.9431\n",
      "Epoch 52/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 1.2301 - categorical_accuracy: 0.9240\n",
      "Epoch 53/400\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 1.2075 - categorical_accuracy: 0.9538\n",
      "Epoch 54/400\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 1.1806 - categorical_accuracy: 0.9620\n",
      "Epoch 55/400\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 1.1652 - categorical_accuracy: 0.9620\n",
      "Epoch 56/400\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 1.1441 - categorical_accuracy: 0.9458\n",
      "Epoch 57/400\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 1.1183 - categorical_accuracy: 0.9618\n",
      "Epoch 58/400\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 1.0944 - categorical_accuracy: 0.9755\n",
      "Epoch 59/400\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 1.0743 - categorical_accuracy: 0.9837\n",
      "Epoch 60/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 1.0527 - categorical_accuracy: 0.9861\n",
      "Epoch 61/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 1.0343 - categorical_accuracy: 0.9757\n",
      "Epoch 62/400\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 1.0236 - categorical_accuracy: 0.9865\n",
      "Epoch 63/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 1.0006 - categorical_accuracy: 0.9946\n",
      "Epoch 64/400\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.9864 - categorical_accuracy: 0.9946\n",
      "Epoch 65/400\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.9653 - categorical_accuracy: 1.0000\n",
      "Epoch 66/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.9493 - categorical_accuracy: 1.0000\n",
      "Epoch 67/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.9354 - categorical_accuracy: 1.0000\n",
      "Epoch 68/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.9130 - categorical_accuracy: 1.0000\n",
      "Epoch 69/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.8996 - categorical_accuracy: 1.0000\n",
      "Epoch 70/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.8885 - categorical_accuracy: 1.0000\n",
      "Epoch 71/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.8727 - categorical_accuracy: 1.0000\n",
      "Epoch 72/400\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.8554 - categorical_accuracy: 1.0000\n",
      "Epoch 73/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.8401 - categorical_accuracy: 1.0000\n",
      "Epoch 74/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 147ms/step - loss: 0.8326 - categorical_accuracy: 1.0000\n",
      "Epoch 75/400\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.8132 - categorical_accuracy: 1.0000\n",
      "Epoch 76/400\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.8047 - categorical_accuracy: 1.0000\n",
      "Epoch 77/400\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.7933 - categorical_accuracy: 1.0000\n",
      "Epoch 78/400\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.7803 - categorical_accuracy: 1.0000\n",
      "Epoch 79/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.7684 - categorical_accuracy: 1.0000\n",
      "Epoch 80/400\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.7536 - categorical_accuracy: 1.0000\n",
      "Epoch 81/400\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.7482 - categorical_accuracy: 1.0000\n",
      "Epoch 82/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.7348 - categorical_accuracy: 1.0000\n",
      "Epoch 83/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.7242 - categorical_accuracy: 1.0000\n",
      "Epoch 84/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.7070 - categorical_accuracy: 1.0000\n",
      "Epoch 85/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.6990 - categorical_accuracy: 1.0000\n",
      "Epoch 86/400\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.6941 - categorical_accuracy: 1.0000\n",
      "Epoch 87/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.6781 - categorical_accuracy: 1.0000\n",
      "Epoch 88/400\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.6693 - categorical_accuracy: 1.0000\n",
      "Epoch 89/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.6563 - categorical_accuracy: 1.0000\n",
      "Epoch 90/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.6509 - categorical_accuracy: 1.0000\n",
      "Epoch 91/400\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.6430 - categorical_accuracy: 1.0000\n",
      "Epoch 92/400\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.6302 - categorical_accuracy: 1.0000\n",
      "Epoch 93/400\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.6217 - categorical_accuracy: 1.0000\n",
      "Epoch 94/400\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.6165 - categorical_accuracy: 1.0000\n",
      "Epoch 95/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.6047 - categorical_accuracy: 1.0000\n",
      "Epoch 96/400\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.5932 - categorical_accuracy: 1.0000\n",
      "Epoch 97/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.5825 - categorical_accuracy: 1.0000\n",
      "Epoch 98/400\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.5823 - categorical_accuracy: 1.0000\n",
      "Epoch 99/400\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.5715 - categorical_accuracy: 1.0000\n",
      "Epoch 100/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.5723 - categorical_accuracy: 1.0000\n",
      "Epoch 101/400\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.5619 - categorical_accuracy: 1.0000\n",
      "Epoch 102/400\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.5508 - categorical_accuracy: 1.0000\n",
      "Epoch 103/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.5439 - categorical_accuracy: 1.0000\n",
      "Epoch 104/400\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.5327 - categorical_accuracy: 1.0000\n",
      "Epoch 105/400\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.5271 - categorical_accuracy: 1.0000\n",
      "Epoch 106/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.5263 - categorical_accuracy: 1.0000\n",
      "Epoch 107/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.5205 - categorical_accuracy: 1.0000\n",
      "Epoch 108/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.5025 - categorical_accuracy: 1.0000\n",
      "Epoch 109/400\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.5006 - categorical_accuracy: 1.0000\n",
      "Epoch 110/400\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.4949 - categorical_accuracy: 1.0000\n",
      "Epoch 111/400\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.4901 - categorical_accuracy: 1.0000\n",
      "Epoch 112/400\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.4857 - categorical_accuracy: 1.0000\n",
      "Epoch 113/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.4730 - categorical_accuracy: 1.0000\n",
      "Epoch 114/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.4768 - categorical_accuracy: 1.0000\n",
      "Epoch 115/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.4681 - categorical_accuracy: 1.0000\n",
      "Epoch 116/400\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.4635 - categorical_accuracy: 1.0000\n",
      "Epoch 117/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.4551 - categorical_accuracy: 1.0000\n",
      "Epoch 118/400\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.4515 - categorical_accuracy: 1.0000\n",
      "Epoch 119/400\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.4410 - categorical_accuracy: 1.0000\n",
      "Epoch 120/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.4388 - categorical_accuracy: 1.0000\n",
      "Epoch 121/400\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.4393 - categorical_accuracy: 1.0000\n",
      "Epoch 122/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.4285 - categorical_accuracy: 1.0000\n",
      "Epoch 123/400\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.4239 - categorical_accuracy: 1.0000\n",
      "Epoch 124/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.4194 - categorical_accuracy: 1.0000\n",
      "Epoch 125/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.4136 - categorical_accuracy: 1.0000\n",
      "Epoch 126/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.4090 - categorical_accuracy: 1.0000\n",
      "Epoch 127/400\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.4037 - categorical_accuracy: 1.0000\n",
      "Epoch 128/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.3990 - categorical_accuracy: 1.0000\n",
      "Epoch 129/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.3985 - categorical_accuracy: 1.0000\n",
      "Epoch 130/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.3932 - categorical_accuracy: 1.0000\n",
      "Epoch 131/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.3879 - categorical_accuracy: 1.0000\n",
      "Epoch 132/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.3809 - categorical_accuracy: 1.0000\n",
      "Epoch 133/400\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.3783 - categorical_accuracy: 1.0000\n",
      "Epoch 134/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.3807 - categorical_accuracy: 1.0000\n",
      "Epoch 135/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.3727 - categorical_accuracy: 1.0000\n",
      "Epoch 136/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.3727 - categorical_accuracy: 1.0000\n",
      "Epoch 137/400\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.3789 - categorical_accuracy: 1.0000\n",
      "Epoch 138/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.3809 - categorical_accuracy: 1.0000\n",
      "Epoch 139/400\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.3687 - categorical_accuracy: 0.9946\n",
      "Epoch 140/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.3866 - categorical_accuracy: 0.9889\n",
      "Epoch 141/400\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.4421 - categorical_accuracy: 0.9780\n",
      "Epoch 142/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.4703 - categorical_accuracy: 0.9615\n",
      "Epoch 143/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.4707 - categorical_accuracy: 0.9587\n",
      "Epoch 144/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.4366 - categorical_accuracy: 0.9781\n",
      "Epoch 145/400\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.5843 - categorical_accuracy: 0.9510\n",
      "Epoch 146/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 155ms/step - loss: 0.4725 - categorical_accuracy: 0.9783\n",
      "Epoch 147/400\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.4827 - categorical_accuracy: 0.9540\n",
      "Epoch 148/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.4067 - categorical_accuracy: 0.9892\n",
      "Epoch 149/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.3848 - categorical_accuracy: 0.9946\n",
      "Epoch 150/400\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.3798 - categorical_accuracy: 0.9972\n",
      "Epoch 151/400\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.3635 - categorical_accuracy: 1.0000\n",
      "Epoch 152/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.3532 - categorical_accuracy: 1.0000\n",
      "Epoch 153/400\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.3440 - categorical_accuracy: 1.0000\n",
      "Epoch 154/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.3357 - categorical_accuracy: 1.0000\n",
      "Epoch 155/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.3267 - categorical_accuracy: 1.0000\n",
      "Epoch 156/400\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.3271 - categorical_accuracy: 1.0000\n",
      "Epoch 157/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.3225 - categorical_accuracy: 1.0000\n",
      "Epoch 158/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.3221 - categorical_accuracy: 1.0000\n",
      "Epoch 159/400\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.3120 - categorical_accuracy: 1.0000\n",
      "Epoch 160/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.3108 - categorical_accuracy: 1.0000\n",
      "Epoch 161/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.3055 - categorical_accuracy: 1.0000\n",
      "Epoch 162/400\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.3018 - categorical_accuracy: 1.0000\n",
      "Epoch 163/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.3021 - categorical_accuracy: 1.0000\n",
      "Epoch 164/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.2983 - categorical_accuracy: 1.0000\n",
      "Epoch 165/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.2959 - categorical_accuracy: 1.0000\n",
      "Epoch 166/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.2913 - categorical_accuracy: 1.0000\n",
      "Epoch 167/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.2937 - categorical_accuracy: 1.0000\n",
      "Epoch 168/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.2843 - categorical_accuracy: 1.0000\n",
      "Epoch 169/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.2824 - categorical_accuracy: 1.0000\n",
      "Epoch 170/400\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.2796 - categorical_accuracy: 1.0000\n",
      "Epoch 171/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.2789 - categorical_accuracy: 1.0000\n",
      "Epoch 172/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.2759 - categorical_accuracy: 1.0000\n",
      "Epoch 173/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.2761 - categorical_accuracy: 1.0000\n",
      "Epoch 174/400\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.2682 - categorical_accuracy: 1.0000\n",
      "Epoch 175/400\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.2665 - categorical_accuracy: 1.0000\n",
      "Epoch 176/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.2661 - categorical_accuracy: 1.0000\n",
      "Epoch 177/400\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.2605 - categorical_accuracy: 1.0000\n",
      "Epoch 178/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.2610 - categorical_accuracy: 1.0000\n",
      "Epoch 179/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.2594 - categorical_accuracy: 1.0000\n",
      "Epoch 180/400\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.2570 - categorical_accuracy: 1.0000\n",
      "Epoch 181/400\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.2552 - categorical_accuracy: 1.0000\n",
      "Epoch 182/400\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.2492 - categorical_accuracy: 1.0000\n",
      "Epoch 183/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.2547 - categorical_accuracy: 1.0000\n",
      "Epoch 184/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.2540 - categorical_accuracy: 1.0000\n",
      "Epoch 185/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.2449 - categorical_accuracy: 1.0000\n",
      "Epoch 186/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.2492 - categorical_accuracy: 1.0000\n",
      "Epoch 187/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.2449 - categorical_accuracy: 1.0000\n",
      "Epoch 188/400\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.2437 - categorical_accuracy: 1.0000\n",
      "Epoch 189/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.2393 - categorical_accuracy: 1.0000\n",
      "Epoch 190/400\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.2375 - categorical_accuracy: 1.0000\n",
      "Epoch 191/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.2358 - categorical_accuracy: 1.0000\n",
      "Epoch 192/400\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.2356 - categorical_accuracy: 1.0000\n",
      "Epoch 193/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.2316 - categorical_accuracy: 1.0000\n",
      "Epoch 194/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.2310 - categorical_accuracy: 1.0000\n",
      "Epoch 195/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.2312 - categorical_accuracy: 1.0000\n",
      "Epoch 196/400\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.2229 - categorical_accuracy: 1.0000\n",
      "Epoch 197/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.2265 - categorical_accuracy: 1.0000\n",
      "Epoch 198/400\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.2229 - categorical_accuracy: 1.0000\n",
      "Epoch 199/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.2207 - categorical_accuracy: 1.0000\n",
      "Epoch 200/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.2210 - categorical_accuracy: 1.0000\n",
      "Epoch 201/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.2190 - categorical_accuracy: 1.0000\n",
      "Epoch 202/400\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.2194 - categorical_accuracy: 1.0000\n",
      "Epoch 203/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.2156 - categorical_accuracy: 1.0000\n",
      "Epoch 204/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.2154 - categorical_accuracy: 1.0000\n",
      "Epoch 205/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.2119 - categorical_accuracy: 1.0000\n",
      "Epoch 206/400\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.2122 - categorical_accuracy: 1.0000\n",
      "Epoch 207/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.2086 - categorical_accuracy: 1.0000\n",
      "Epoch 208/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.2121 - categorical_accuracy: 1.0000\n",
      "Epoch 209/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.2096 - categorical_accuracy: 1.0000\n",
      "Epoch 210/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.2031 - categorical_accuracy: 1.0000\n",
      "Epoch 211/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.2066 - categorical_accuracy: 1.0000\n",
      "Epoch 212/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.2048 - categorical_accuracy: 1.0000\n",
      "Epoch 213/400\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.2041 - categorical_accuracy: 1.0000\n",
      "Epoch 214/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.2014 - categorical_accuracy: 1.0000\n",
      "Epoch 215/400\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.1979 - categorical_accuracy: 1.0000\n",
      "Epoch 216/400\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.1974 - categorical_accuracy: 1.0000\n",
      "Epoch 217/400\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1950 - categorical_accuracy: 1.0000\n",
      "Epoch 218/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1922 - categorical_accuracy: 1.0000\n",
      "Epoch 219/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1951 - categorical_accuracy: 1.0000\n",
      "Epoch 220/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.1926 - categorical_accuracy: 1.0000\n",
      "Epoch 221/400\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.1880 - categorical_accuracy: 1.0000\n",
      "Epoch 222/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.1914 - categorical_accuracy: 1.0000\n",
      "Epoch 223/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1911 - categorical_accuracy: 1.0000\n",
      "Epoch 224/400\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.1905 - categorical_accuracy: 1.0000\n",
      "Epoch 225/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.1872 - categorical_accuracy: 1.0000\n",
      "Epoch 226/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1861 - categorical_accuracy: 1.0000\n",
      "Epoch 227/400\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.1828 - categorical_accuracy: 1.0000\n",
      "Epoch 228/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1821 - categorical_accuracy: 1.0000\n",
      "Epoch 229/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1833 - categorical_accuracy: 1.0000\n",
      "Epoch 230/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1821 - categorical_accuracy: 1.0000\n",
      "Epoch 231/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1785 - categorical_accuracy: 1.0000\n",
      "Epoch 232/400\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.1770 - categorical_accuracy: 1.0000\n",
      "Epoch 233/400\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.1767 - categorical_accuracy: 1.0000\n",
      "Epoch 234/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.1771 - categorical_accuracy: 1.0000\n",
      "Epoch 235/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.1754 - categorical_accuracy: 1.0000\n",
      "Epoch 236/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1750 - categorical_accuracy: 1.0000\n",
      "Epoch 237/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.1718 - categorical_accuracy: 1.0000\n",
      "Epoch 238/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.1726 - categorical_accuracy: 1.0000\n",
      "Epoch 239/400\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.1714 - categorical_accuracy: 1.0000\n",
      "Epoch 240/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1716 - categorical_accuracy: 1.0000\n",
      "Epoch 241/400\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.1658 - categorical_accuracy: 1.0000\n",
      "Epoch 242/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1688 - categorical_accuracy: 1.0000\n",
      "Epoch 243/400\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.1666 - categorical_accuracy: 1.0000\n",
      "Epoch 244/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.1636 - categorical_accuracy: 1.0000\n",
      "Epoch 245/400\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.1655 - categorical_accuracy: 1.0000\n",
      "Epoch 246/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1662 - categorical_accuracy: 1.0000\n",
      "Epoch 247/400\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.1633 - categorical_accuracy: 1.0000\n",
      "Epoch 248/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.1624 - categorical_accuracy: 1.0000\n",
      "Epoch 249/400\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.1623 - categorical_accuracy: 1.0000\n",
      "Epoch 250/400\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.1621 - categorical_accuracy: 1.0000\n",
      "Epoch 251/400\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.1601 - categorical_accuracy: 1.0000\n",
      "Epoch 252/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1575 - categorical_accuracy: 1.0000\n",
      "Epoch 253/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1567 - categorical_accuracy: 1.0000\n",
      "Epoch 254/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.1558 - categorical_accuracy: 1.0000\n",
      "Epoch 255/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1546 - categorical_accuracy: 1.0000\n",
      "Epoch 256/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1532 - categorical_accuracy: 1.0000\n",
      "Epoch 257/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.1541 - categorical_accuracy: 1.0000\n",
      "Epoch 258/400\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.1526 - categorical_accuracy: 1.0000\n",
      "Epoch 259/400\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1500 - categorical_accuracy: 1.0000\n",
      "Epoch 260/400\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.1519 - categorical_accuracy: 1.0000\n",
      "Epoch 261/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.1495 - categorical_accuracy: 1.0000\n",
      "Epoch 262/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1476 - categorical_accuracy: 1.0000\n",
      "Epoch 263/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1473 - categorical_accuracy: 1.0000\n",
      "Epoch 264/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.1471 - categorical_accuracy: 1.0000\n",
      "Epoch 265/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1473 - categorical_accuracy: 1.0000\n",
      "Epoch 266/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1453 - categorical_accuracy: 1.0000\n",
      "Epoch 267/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.1464 - categorical_accuracy: 1.0000\n",
      "Epoch 268/400\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.1465 - categorical_accuracy: 1.0000\n",
      "Epoch 269/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.1444 - categorical_accuracy: 1.0000\n",
      "Epoch 270/400\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.1440 - categorical_accuracy: 1.0000\n",
      "Epoch 271/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.1422 - categorical_accuracy: 1.0000\n",
      "Epoch 272/400\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1415 - categorical_accuracy: 1.0000\n",
      "Epoch 273/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.1418 - categorical_accuracy: 1.0000\n",
      "Epoch 274/400\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1393 - categorical_accuracy: 1.0000\n",
      "Epoch 275/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1401 - categorical_accuracy: 1.0000\n",
      "Epoch 276/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1373 - categorical_accuracy: 1.0000\n",
      "Epoch 277/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.1376 - categorical_accuracy: 1.0000\n",
      "Epoch 278/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1373 - categorical_accuracy: 1.0000\n",
      "Epoch 279/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.1361 - categorical_accuracy: 1.0000\n",
      "Epoch 280/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1372 - categorical_accuracy: 1.0000\n",
      "Epoch 281/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1345 - categorical_accuracy: 1.0000\n",
      "Epoch 282/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1339 - categorical_accuracy: 1.0000\n",
      "Epoch 283/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1326 - categorical_accuracy: 1.0000\n",
      "Epoch 284/400\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.1317 - categorical_accuracy: 1.0000\n",
      "Epoch 285/400\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.1318 - categorical_accuracy: 1.0000\n",
      "Epoch 286/400\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.1323 - categorical_accuracy: 1.0000\n",
      "Epoch 287/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1307 - categorical_accuracy: 1.0000\n",
      "Epoch 288/400\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.1294 - categorical_accuracy: 1.0000\n",
      "Epoch 289/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.1300 - categorical_accuracy: 1.0000\n",
      "Epoch 290/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1274 - categorical_accuracy: 1.0000\n",
      "Epoch 291/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.1281 - categorical_accuracy: 1.0000\n",
      "Epoch 292/400\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1262 - categorical_accuracy: 1.0000\n",
      "Epoch 293/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1277 - categorical_accuracy: 1.0000\n",
      "Epoch 294/400\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.1251 - categorical_accuracy: 1.0000\n",
      "Epoch 295/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1249 - categorical_accuracy: 1.0000\n",
      "Epoch 296/400\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.1249 - categorical_accuracy: 1.0000\n",
      "Epoch 297/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1238 - categorical_accuracy: 1.0000\n",
      "Epoch 298/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.1209 - categorical_accuracy: 1.0000\n",
      "Epoch 299/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1228 - categorical_accuracy: 1.0000\n",
      "Epoch 300/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.1228 - categorical_accuracy: 1.0000\n",
      "Epoch 301/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1221 - categorical_accuracy: 1.0000\n",
      "Epoch 302/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.1212 - categorical_accuracy: 1.0000\n",
      "Epoch 303/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1184 - categorical_accuracy: 1.0000\n",
      "Epoch 304/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.1202 - categorical_accuracy: 1.0000\n",
      "Epoch 305/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.1181 - categorical_accuracy: 1.0000\n",
      "Epoch 306/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.1200 - categorical_accuracy: 1.0000\n",
      "Epoch 307/400\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.1205 - categorical_accuracy: 1.0000\n",
      "Epoch 308/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.1177 - categorical_accuracy: 1.0000\n",
      "Epoch 309/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.1166 - categorical_accuracy: 1.0000\n",
      "Epoch 310/400\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.1157 - categorical_accuracy: 1.0000\n",
      "Epoch 311/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.1143 - categorical_accuracy: 1.0000\n",
      "Epoch 312/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1150 - categorical_accuracy: 1.0000\n",
      "Epoch 313/400\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.1142 - categorical_accuracy: 1.0000\n",
      "Epoch 314/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.1151 - categorical_accuracy: 1.0000\n",
      "Epoch 315/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.1120 - categorical_accuracy: 1.0000\n",
      "Epoch 316/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.1134 - categorical_accuracy: 1.0000\n",
      "Epoch 317/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.1127 - categorical_accuracy: 1.0000\n",
      "Epoch 318/400\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.1110 - categorical_accuracy: 1.0000\n",
      "Epoch 319/400\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.1117 - categorical_accuracy: 1.0000\n",
      "Epoch 320/400\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.1119 - categorical_accuracy: 1.0000\n",
      "Epoch 321/400\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.1101 - categorical_accuracy: 1.0000\n",
      "Epoch 322/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.1106 - categorical_accuracy: 1.0000\n",
      "Epoch 323/400\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.1106 - categorical_accuracy: 1.0000\n",
      "Epoch 324/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.1097 - categorical_accuracy: 1.0000\n",
      "Epoch 325/400\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.1080 - categorical_accuracy: 1.0000\n",
      "Epoch 326/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.1087 - categorical_accuracy: 1.0000\n",
      "Epoch 327/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.1083 - categorical_accuracy: 1.0000\n",
      "Epoch 328/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1065 - categorical_accuracy: 1.0000\n",
      "Epoch 329/400\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.1065 - categorical_accuracy: 1.0000\n",
      "Epoch 330/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.1064 - categorical_accuracy: 1.0000\n",
      "Epoch 331/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.1043 - categorical_accuracy: 1.0000\n",
      "Epoch 332/400\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.1050 - categorical_accuracy: 1.0000\n",
      "Epoch 333/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1036 - categorical_accuracy: 1.0000\n",
      "Epoch 334/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1031 - categorical_accuracy: 1.0000\n",
      "Epoch 335/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1028 - categorical_accuracy: 1.0000\n",
      "Epoch 336/400\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1022 - categorical_accuracy: 1.0000\n",
      "Epoch 337/400\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.1033 - categorical_accuracy: 1.0000\n",
      "Epoch 338/400\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.1017 - categorical_accuracy: 1.0000\n",
      "Epoch 339/400\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1019 - categorical_accuracy: 1.0000\n",
      "Epoch 340/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.1014 - categorical_accuracy: 1.0000\n",
      "Epoch 341/400\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.1009 - categorical_accuracy: 1.0000\n",
      "Epoch 342/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0998 - categorical_accuracy: 1.0000\n",
      "Epoch 343/400\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1002 - categorical_accuracy: 1.0000\n",
      "Epoch 344/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.0986 - categorical_accuracy: 1.0000\n",
      "Epoch 345/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.0989 - categorical_accuracy: 1.0000\n",
      "Epoch 346/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0990 - categorical_accuracy: 1.0000\n",
      "Epoch 347/400\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.0968 - categorical_accuracy: 1.0000\n",
      "Epoch 348/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0989 - categorical_accuracy: 1.0000\n",
      "Epoch 349/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0966 - categorical_accuracy: 1.0000\n",
      "Epoch 350/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0964 - categorical_accuracy: 1.0000\n",
      "Epoch 351/400\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.0963 - categorical_accuracy: 1.0000\n",
      "Epoch 352/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0963 - categorical_accuracy: 1.0000\n",
      "Epoch 353/400\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.0955 - categorical_accuracy: 1.0000\n",
      "Epoch 354/400\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0952 - categorical_accuracy: 1.0000\n",
      "Epoch 355/400\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0946 - categorical_accuracy: 1.0000\n",
      "Epoch 356/400\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0953 - categorical_accuracy: 1.0000\n",
      "Epoch 357/400\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.0949 - categorical_accuracy: 1.0000\n",
      "Epoch 358/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0934 - categorical_accuracy: 1.0000\n",
      "Epoch 359/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0935 - categorical_accuracy: 1.0000\n",
      "Epoch 360/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0923 - categorical_accuracy: 1.0000\n",
      "Epoch 361/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0931 - categorical_accuracy: 1.0000\n",
      "Epoch 362/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0935 - categorical_accuracy: 1.0000\n",
      "Epoch 363/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0921 - categorical_accuracy: 1.0000\n",
      "Epoch 364/400\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0907 - categorical_accuracy: 1.0000\n",
      "Epoch 365/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0915 - categorical_accuracy: 1.0000\n",
      "Epoch 366/400\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0908 - categorical_accuracy: 1.0000\n",
      "Epoch 367/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0895 - categorical_accuracy: 1.0000\n",
      "Epoch 368/400\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.0897 - categorical_accuracy: 1.0000\n",
      "Epoch 369/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0899 - categorical_accuracy: 1.0000\n",
      "Epoch 370/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0886 - categorical_accuracy: 1.0000\n",
      "Epoch 371/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0892 - categorical_accuracy: 1.0000\n",
      "Epoch 372/400\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.0898 - categorical_accuracy: 1.0000\n",
      "Epoch 373/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0875 - categorical_accuracy: 1.0000\n",
      "Epoch 374/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0873 - categorical_accuracy: 1.0000\n",
      "Epoch 375/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0881 - categorical_accuracy: 1.0000\n",
      "Epoch 376/400\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.0873 - categorical_accuracy: 1.0000\n",
      "Epoch 377/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0866 - categorical_accuracy: 1.0000\n",
      "Epoch 378/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0864 - categorical_accuracy: 1.0000\n",
      "Epoch 379/400\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0864 - categorical_accuracy: 1.0000\n",
      "Epoch 380/400\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0865 - categorical_accuracy: 1.0000\n",
      "Epoch 381/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0851 - categorical_accuracy: 1.0000\n",
      "Epoch 382/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0849 - categorical_accuracy: 1.0000\n",
      "Epoch 383/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0846 - categorical_accuracy: 1.0000\n",
      "Epoch 384/400\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.0841 - categorical_accuracy: 1.0000\n",
      "Epoch 385/400\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0842 - categorical_accuracy: 1.0000\n",
      "Epoch 386/400\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.0838 - categorical_accuracy: 1.0000\n",
      "Epoch 387/400\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.0839 - categorical_accuracy: 1.0000\n",
      "Epoch 388/400\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.0827 - categorical_accuracy: 1.0000\n",
      "Epoch 389/400\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0816 - categorical_accuracy: 1.0000\n",
      "Epoch 390/400\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.0830 - categorical_accuracy: 1.0000\n",
      "Epoch 391/400\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0832 - categorical_accuracy: 1.0000\n",
      "Epoch 392/400\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.0822 - categorical_accuracy: 1.0000\n",
      "Epoch 393/400\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.0821 - categorical_accuracy: 1.0000\n",
      "Epoch 394/400\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0819 - categorical_accuracy: 1.0000\n",
      "Epoch 395/400\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.0806 - categorical_accuracy: 1.0000\n",
      "Epoch 396/400\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.0814 - categorical_accuracy: 1.0000\n",
      "Epoch 397/400\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.0796 - categorical_accuracy: 1.0000\n",
      "Epoch 398/400\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.0812 - categorical_accuracy: 1.0000\n",
      "Epoch 399/400\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.0792 - categorical_accuracy: 1.0000\n",
      "Epoch 400/400\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.0781 - categorical_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "h = md.fit(X_train, y_train, batch_size=128,\n",
    "         epochs = 400, callbacks=[tb_callback]) # tensorboard_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_12 (LSTM)               (None, 50, 128)           198144    \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 50, 64)            49408     \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 15)                495       \n",
      "=================================================================\n",
      "Total params: 264,655\n",
      "Trainable params: 264,655\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "md.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.plot(range(1, 401, 1),\n",
    "         h.history['categorical_accuracy'],\n",
    "         label='categorical_accuracy'\n",
    "         )\n",
    "\n",
    "plt.plot(range(1, 401, 1),\n",
    "         h.history['loss'],\n",
    "         label='loss'\n",
    "         )\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = md.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "함께 식사할까요\n",
      "함께 식사할까요\n",
      "==============================\n",
      "미안합니다\n",
      "미안합니다\n",
      "==============================\n",
      "안녕하세요 만나서 반갑습니다\n",
      "안녕하세요 만나서 반갑습니다\n",
      "==============================\n",
      "감사합니다\n",
      "감사합니다\n",
      "==============================\n",
      "평화\n",
      "평화\n",
      "==============================\n",
      "즐겁다\n",
      "배고프다\n",
      "==============================\n",
      "잘 지냈어요\n",
      "잘 지냈어요\n",
      "==============================\n",
      "화장실\n",
      "화장실\n",
      "==============================\n",
      "함께 식사할까요\n",
      "함께 식사할까요\n",
      "==============================\n",
      "잘 지냈어요\n",
      "잘 지냈어요\n",
      "==============================\n",
      "귀여워요\n",
      "귀여워요\n",
      "==============================\n",
      "함께 식사할까요\n",
      "함께 식사할까요\n",
      "==============================\n",
      "즐겁다\n",
      "즐겁다\n",
      "==============================\n",
      "즐겁다\n",
      "즐겁다\n",
      "==============================\n",
      "잘 지냈어요\n",
      "잘 지냈어요\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(actions)):\n",
    "    actions[np.argmax(res[i])]\n",
    "    actions[np.argmax(y_test[i])]\n",
    "    print(actions[np.argmax(res[i])])\n",
    "    print(actions[np.argmax(y_test[i])])\n",
    "    print(\"==============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# actions[np.argmax(res[4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actions[np.argmax(y_test[8])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.save('HandSign_plus_text.h5')  # 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#md.load_weights('HandSign1_word.h5')  # 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 재평가\n",
    "#loss,acc = md.evaluate(test_images,  test_labels, verbose=2)\n",
    "#print(\"복원된 모델의 정확도: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix,accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = md.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = np.argmax(y_train, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[224,   0],\n",
       "        [  0,  16]],\n",
       "\n",
       "       [[224,   0],\n",
       "        [  0,  16]],\n",
       "\n",
       "       [[224,   0],\n",
       "        [  0,  16]],\n",
       "\n",
       "       [[224,   0],\n",
       "        [  0,  16]],\n",
       "\n",
       "       [[222,   0],\n",
       "        [  0,  18]],\n",
       "\n",
       "       [[224,   0],\n",
       "        [  0,  16]],\n",
       "\n",
       "       [[224,   0],\n",
       "        [  0,  16]],\n",
       "\n",
       "       [[226,   0],\n",
       "        [  0,  14]],\n",
       "\n",
       "       [[223,   0],\n",
       "        [  0,  17]],\n",
       "\n",
       "       [[226,   0],\n",
       "        [  0,  14]],\n",
       "\n",
       "       [[223,   0],\n",
       "        [  0,  17]],\n",
       "\n",
       "       [[226,   0],\n",
       "        [  0,  14]],\n",
       "\n",
       "       [[222,   0],\n",
       "        [  0,  18]],\n",
       "\n",
       "       [[222,   0],\n",
       "        [  0,  18]],\n",
       "\n",
       "       [[226,   0],\n",
       "        [  0,  14]]], dtype=int64)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 20ms/step - loss: 0.2344 - categorical_accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2344253808259964, 0.9666666388511658]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = [(245,117,16),(117,245,16),(16,117,245),(245,117,16),(117,245,16),(16,117,245),(245,117,16),(117,245,16),\n",
    "#           (16,117,245),(245,117,16)]\n",
    "# #colors = [(245,117,16),(117,245,16),(16,117,245),(245,117,16),(117,245,16)]\n",
    "# # ,(245,117,16),(117,245,16),(16,117,245),(245,117,16)\n",
    "# #          ,(117,245,16),(16,117,245),(245,117,16),(117,245,16),(16,117,245)\n",
    "# def prob_viz(res,actions,input_frame,colors):\n",
    "#     output_frame = input_frame.copy()\n",
    "#     for num, prob in enumerate(res):\n",
    "#         cv2.rectangle(output_frame, (0,60+num*40),(int(prob*100),90+num*40),colors[num],-1)\n",
    "#         cv2.putText(output_frame, actions[num],(0,85+num*40),cv2.FONT_HERSHEY_SIMPLEX,1,\n",
    "#                     (255,255,255),2,cv2.LINE_AA)\n",
    "        \n",
    "#     return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -*- coding : utf-8 -*-\n",
    "# import sys\n",
    "# print(sys.getdefaultencoding())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요 만나서 반갑습니다\n",
      "안녕하세요 만나서 반갑습니다\n",
      "Finish\n",
      "안녕하세요 만나서 반갑습니다\n"
     ]
    }
   ],
   "source": [
    "# -*- coding : utf-8 -*-\n",
    "import cv2\n",
    "from PIL import ImageFont, ImageDraw, Image  # 한글 출력 임포트\n",
    "# 1. New detection variables\n",
    "sequence = []\n",
    "sentence = []\n",
    "threshold = 0.7\n",
    "predictions = []\n",
    "\n",
    "def most_frequent(data):\n",
    "    return max(data, key=data.count)\n",
    "cnt = 0\n",
    "result_actions = 0\n",
    "\n",
    "#word=['감사합니다','귀여워요','괜찮아요','미안합니다','기다려요']\n",
    "b,g,r,a = 0,0,0,10\n",
    "# fontpath = \"fonts/gulim.ttc\"\n",
    "fontpath = \"fonts/H2MKPB.TTF\"\n",
    "font = ImageFont.truetype(fontpath, 50)\n",
    "\n",
    "cap = cv2.VideoCapture(\"./img/Ntm.mp4\")\n",
    "#cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:   \n",
    "    while cap.isOpened():\n",
    "    \n",
    "        # read feed\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            #print(\"비디오 읽기 실패 / 비디오 모두 읽음\")\n",
    "            print(\"Finish\")\n",
    "            cap.release()   # 비디오 읽기 종료\n",
    "            cv2.destroyAllWindows()  # 새로 연 창을 모두 닫아줌\n",
    "            break\n",
    "        \n",
    "        frame = imutils.resize(frame, width=800)\n",
    "            \n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame,holistic)\n",
    "#         print(results)\n",
    "        \n",
    "#        image = Image.fromarray(image)\n",
    "#        draw = ImageDraw.Draw(image)\n",
    "#        draw.text(xy=(10,15), text=actions[np.argmax(res)], font=font, fill=(255,255,255))\n",
    "        image=np.array(image)\n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "        \n",
    "        img_pil = Image.fromarray(image)\n",
    "        draw = ImageDraw.Draw(img_pil)\n",
    "        \n",
    "        #2. Prediction logic\n",
    "        keypoints = extract_keypoints(results)\n",
    "#        sequence.insert(0,keypoints)\n",
    "#        sequence = sequence[:30]\n",
    "        sequence.append(keypoints)\n",
    "#        sequence = sequence[-40:]\n",
    "        \n",
    "#        label = actions[np.argmax(res)]\n",
    "        if len(sequence) == 50 :  # 30 프레임 \n",
    "                 #np.expand_dims : (s_num,50,1662)을 캡슐화\n",
    "            res = md.predict(np.expand_dims(sequence, axis=0))[0]            \n",
    "            print(actions[np.argmax(res)])\n",
    "            predictions.append(np.argmax(res))\n",
    "            sequence = []\n",
    "        \n",
    "# # # #         # 3. Viz logic\n",
    "#         if np.unique(predictions[:10]) ==np.argmax(res): \n",
    "        \n",
    "#         if res[np.argmax(res)] > threshold: # 정확도                \n",
    "#             if len(sentence) > 0:\n",
    "#                 if actions[np.argmax(res)] != sentence[-1]:\n",
    "#                     sentence.append(actions[np.argmax(res)])\n",
    "# #                     print(actions[np.argmax(res)])\n",
    "#             else :                               \n",
    "#                 sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "#         if len(sentence) > 2 : #화면출력 글자 수\n",
    "#             sentence = sentence[-2:]\n",
    "#                 #draw.text(xy=(10,15), text=sentence, font=font, fill=(255,255,255))\n",
    "#              # VIz probabilities\n",
    "# #        image = prob_viz(res, actions, image, colors)\n",
    "#               draw.text(xy=(10,15), text=actions[np.argmax(res)], font=font, fill=(255,255,255))\n",
    "\n",
    "#         cv2.rectangle(image, (0,0), (640,40), (245, 117, 16), -1)\n",
    "#         if sentence != [] :                        \n",
    "#             cv2.putText(image, sentence, (3,30),\n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX,1, (255,255,255), 2, cv2.LINE_AA)\n",
    "            \n",
    "#         if result_actions == label:            \n",
    "#             cnt += 1\n",
    "# #         elif result_actions != label:\n",
    "# #             cnt = 0\n",
    "        \n",
    "#         result_actions = \"귀여워요\"\n",
    "#         if cnt >= 15:\n",
    "#             #print(result_actions)\n",
    "        draw.text((10, 10), actions[np.argmax(res)] , font=font, fill=(b,g,r,a))\n",
    "        image = np.array(img_pil)\n",
    "            \n",
    "        \n",
    "        # show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "        \n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) == 27:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "            \n",
    "        \n",
    "    #print(actions[np.argmax(res)])\n",
    "#     def most_frequent(data):\n",
    "#         count_list=[]\n",
    "\n",
    "#         for x in data: \n",
    "#             count_list.append(data.count(x))\n",
    " \n",
    "#         return data[count_list.index(max(count_list))]\n",
    "\n",
    "#     print(most_frequent(sequence))\n",
    "    print(actions[np.argmax(res)])\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "#     print(most_frequent(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5001/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [13/Aug/2021 15:04:19] \"\u001b[32mGET / HTTP/1.1\u001b[0m\" 302 -\n",
      "127.0.0.1 - - [13/Aug/2021 15:12:00] \"\u001b[32mGET / HTTP/1.1\u001b[0m\" 302 -\n",
      "127.0.0.1 - - [13/Aug/2021 15:13:00] \"\u001b[32mGET / HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "from flask import redirect\n",
    "\n",
    "app = Flask(__name__) \n",
    "\n",
    "@app.route('/')\n",
    "def index():     \n",
    "    # JSP로 만들어진 웹 페이지에 데이터 전송\n",
    "    # GET방식으로 데이터 전달 시 쿼리스트링 기술 활용\n",
    "    #  -> ?name=value&name=value&...\n",
    "    url = 'http://localhost:8081/muscle/index.do?data='+actions[np.argmax(res)]\n",
    "    return redirect(url)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='127.0.0.1', port='5001') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. New detection variables\n",
    "# sequence = []\n",
    "# sentence = []\n",
    "# predictions=[]\n",
    "# threshold = 0.6\n",
    "\n",
    "# # cap = cv2.VideoCapture(0)\n",
    "# # cap = cv2.VideoCapture(\"D:\\\\aihub\\\\수어 영상\\\\1.Training\\\\[원천]01_real_word_video\\\\01\\\\NIA_SL_WORD1504_REAL01_F.mp4\")\n",
    "# # cap = cv2.VideoCapture(\"C:\\\\Users\\\\21SMT41\\\\Desktop\\\\deep_ex\\\\eeee\\\\NIA_SL_WORD1505_REAL01_R.mp4\")\n",
    "# cap = cv2.VideoCapture(\"C:\\\\Users\\\\21SMT41\\\\Desktop\\\\web_video\\\\cocohappy.mp4\")\n",
    "\n",
    "# cv2.waitKey(3000)\n",
    "# # Set mediapipe model\n",
    "# with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:   \n",
    "#     while cap.isOpened():\n",
    "        \n",
    "#         # read feed\n",
    "        \n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             print(\"비디오 읽기 실패 / 비디오 모두 읽음\")\n",
    "#             cap.release()   # 비디오 읽기 종료\n",
    "#             cv2.destroyAllWindows()  # 새로 연 창을 모두 닫아줌\n",
    "#             break\n",
    "            \n",
    "#         # Make detections\n",
    "#         image, results = mediapipe_detection(frame,holistic)\n",
    "# #         print(results)\n",
    "        \n",
    "#         # Draw landmarks\n",
    "#         draw_styled_landmarks(image, results)\n",
    "        \n",
    "#         #2. Prediction logic\n",
    "#         keypoints = extract_keypoints(results)\n",
    "# #         sequence.insert(0,keypoints)\n",
    "# #        sequence = sequence[:30]\n",
    "#         sequence.append(keypoints)\n",
    "# #         sequence = sequence[-50:]\n",
    "        \n",
    "#         if len(sequence) == 100 :\n",
    "#             res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "#             print(actions[np.argmax(res)])\n",
    "#             sentence = actions[np.argmax(res)]\n",
    "#             sequence=[]\n",
    "# #             predictions.append(np.argmax(res))\n",
    "           \n",
    "           \n",
    "#         # 3. Viz logic\n",
    "# #         if np.unique(predictions[-10:])==np.argmax(res):\n",
    "          \n",
    "        \n",
    "# #         if res[np.argmax(res)] > threshold:\n",
    "# #             if len(sentence) > 0:\n",
    "# #                 if actions[np.argmax(res)] != sentence[-1]:\n",
    "# #                     sentence.append(actions[np.argmax(res)])\n",
    "# #             else : \n",
    "# #                 sentence.append(actions[np.argmax(res)])\n",
    "            \n",
    "# #         if len(sentence) >3 :\n",
    "# #             sentence = sentence[-3:]\n",
    "               \n",
    "# #         # VIz probabilities\n",
    "# #         image = prob_viz(res, actions, image, colors)\n",
    "#         cv2.rectangle(image, (0,0), (640,40), (245, 117, 16), -1)\n",
    "#         if sentence != [] :\n",
    "            \n",
    "#             cv2.putText(image, sentence, (3,30),\n",
    "#                       cv2.FONT_HERSHEY_SIMPLEX,1, (255,255,255), 2, cv2.LINE_AA)\n",
    "                 \n",
    "        \n",
    "# #         \n",
    "\n",
    "#         # show to screen\n",
    "#         cv2.imshow('OpenCV Feed', image)\n",
    "        \n",
    "#         # Break gracefully\n",
    "#         if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#             break\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "# # print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "손이 너무 아파요\n"
     ]
    }
   ],
   "source": [
    "# # -*- coding : utf-8 -*-\n",
    "# import cv2\n",
    "# from PIL import ImageFont, ImageDraw, Image  # 한글 출력 임포트\n",
    "# # 1. New detection variables\n",
    "# sequence = []\n",
    "# sentence = []\n",
    "# threshold = 0.7\n",
    "# predictions = []\n",
    "\n",
    "# def most_frequent(data):\n",
    "#     return max(data, key=data.count)\n",
    "# cnt = 0\n",
    "# result_actions = 0\n",
    "\n",
    "# word=['감사합니다','귀여워요','괜찮아요','미안합니다','기다려요']\n",
    "# b,g,r,a = 0,0,0,10\n",
    "# fontpath = \"fonts/gulim.ttc\"\n",
    "# font = ImageFont.truetype(fontpath, 40)\n",
    "\n",
    "# cap = cv2.VideoCapture(\"./img/A2.mp4\")\n",
    "# #cap = cv2.VideoCapture(0)\n",
    "# # Set mediapipe model\n",
    "# with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:   \n",
    "#     while cap.isOpened():\n",
    "    \n",
    "#         # read feed\n",
    "        \n",
    "#         ret, frame = cap.read()\n",
    "#         frame = imutils.resize(frame, width=800)\n",
    "#         if not ret:\n",
    "#             #print(\"비디오 읽기 실패 / 비디오 모두 읽음\")\n",
    "#             print(\"Finish\")\n",
    "#             cap.release()   # 비디오 읽기 종료\n",
    "#             cv2.destroyAllWindows()  # 새로 연 창을 모두 닫아줌\n",
    "#             break\n",
    "            \n",
    "#         # Make detections\n",
    "#         image, results = mediapipe_detection(frame,holistic)\n",
    "#         print(results)\n",
    "        \n",
    "# #         image = Image.fromarray(image)\n",
    "# #         draw = ImageDraw.Draw(image)\n",
    "# #         draw.text(xy=(10,15), text=actions[np.argmax(res)], font=font, fill=(255,255,255))\n",
    "# #         image=np.array(image)\n",
    "#         # Draw landmarks\n",
    "#         draw_styled_landmarks(image, results)\n",
    "        \n",
    "#         img_pil = Image.fromarray(image)\n",
    "#         draw = ImageDraw.Draw(img_pil)\n",
    "#         #label = actions[np.argmax(res)]\n",
    "        \n",
    "#         #2. Prediction logic\n",
    "#         keypoints = extract_keypoints(results)\n",
    "# #        sequence.insert(0,keypoints)\n",
    "# #        sequence = sequence[:30]\n",
    "#         sequence.append(keypoints)\n",
    "# #        sequence = sequence[-100:]\n",
    "        \n",
    "        \n",
    "#         if len(sequence) == 100 :  # 30 프레임 \n",
    "#                  #np.expand_dims : (s_num,50,1662)을 캡슐화\n",
    "#             res = md.predict(np.expand_dims(sequence, axis=0))[0]            \n",
    "#             print(actions[np.argmax(res)])\n",
    "#             predictions.append(np.argmax(res))\n",
    "        \n",
    "# # # #         # 3. Viz logic\n",
    "# #        if np.unique(predictions[:10]) ==np.argmax(res): \n",
    "        \n",
    "# #         if res[np.argmax(res)] > threshold: # 정확도                \n",
    "# #             if len(sentence) > 0:\n",
    "# #                 if actions[np.argmax(res)] != sentence[-1]:\n",
    "# #                     sentence.append(actions[np.argmax(res)])\n",
    "# #                     print(actions[np.argmax(res)])\n",
    "# #             else :                               \n",
    "# #                 sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "# #         if len(sentence) > 2 : #화면출력 글자 수\n",
    "# #             sentence = sentence[-2:]\n",
    "# #                 #draw.text(xy=(10,15), text=sentence, font=font, fill=(255,255,255))\n",
    "# #     #         # VIz probabilities\n",
    "# # #        image = prob_viz(res, actions, image, colors)\n",
    "# #     #         draw.text(xy=(10,15), text=actions[np.argmax(res)], font=font, fill=(255,255,255))  \n",
    "#         cv2.rectangle(image, (0,0), (640,40), (245, 117, 16), -1)\n",
    "# #         cv2.putText(image, ' '.join(sentence), (3,30),\n",
    "# #                     cv2.FONT_HERSHEY_SIMPLEX,1, (255,255,255), 2, cv2.LINE_AA)\n",
    "# #         if result_actions == label:            \n",
    "# #             cnt += 1\n",
    "# # #         elif result_actions != label:\n",
    "# # #             cnt = 0\n",
    "        \n",
    "# #         result_actions = \"귀여워요\"\n",
    "# #         if cnt >= 15:\n",
    "# #             #print(result_actions)\n",
    "# #             draw.text((10, 10), actions[np.argmax(res)] , font=font, fill=(b,g,r,a))\n",
    "# #             image = np.array(img_pil)\n",
    "            \n",
    "        \n",
    "#         # show to screen\n",
    "#         cv2.imshow('OpenCV Feed', image)\n",
    "        \n",
    "#         # Break gracefully\n",
    "#         if cv2.waitKey(10) == 27:\n",
    "#             break\n",
    "            \n",
    "        \n",
    "#     #print(actions[np.argmax(res)])\n",
    "# #     def most_frequent(data):\n",
    "# #         count_list=[]\n",
    "\n",
    "# #         for x in data: \n",
    "# #             count_list.append(data.count(x))\n",
    " \n",
    "# #         return data[count_list.index(max(count_list))]\n",
    "\n",
    "# #     print(most_frequent(sequence))\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "# #    print(most_frequent(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions[np.argmax(res)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.predict(np.expand_dims(sequence, axis=0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(sequence, axis=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flask import Flask\n",
    "# from flask import request, redirect\n",
    "\n",
    "# app = Flask(__name__) \n",
    "\n",
    "# @app.route('/', methods=['GET','POST']) #/wondu\n",
    "# def index():   #wondu  \n",
    "       \n",
    "#     if request.method == 'GET':\n",
    "# #         cf1 = str(request.args['chk_info1'])\n",
    "# #         cf2 = str(request.args['chk_info2'])\n",
    "# #         cf3 = int(request.args['chk_info3'])\n",
    "       \n",
    "#         #df.iloc[list(similar_indexes)].sort_values('랭킹', ascending=True)[:top_n]\n",
    "# #         similar_wondu = find_sim_wondu(wondu, wondu_sim_sorted_ind, cf1,cf2,cf3,3) # 견과류향, 시티로스팅 , 바디감(2)에 가까운걸 5개뽑아줘!!\n",
    "# #         coffee=similar_wondu['원두이름']\n",
    "# #         print(cf1, cf2, cf3)\n",
    "\n",
    "#         # result = model() = request.args['num1']\n",
    "        \n",
    "        \n",
    "#     else:\n",
    "# #         cf1 = str(request.form['chk_info1'])\n",
    "# #         cf2 = str(request.form['chk_info2'])\n",
    "# #         cf3 = int(request.form['chk_info3'])\n",
    "# #         print(cf1, cf2, cf3)\n",
    "#         #df.iloc[list(similar_indexes)].sort_values('랭킹', ascending=True)[:top_n]\n",
    "# #         similar_wondu = find_sim_wondu(wondu, wondu_sim_sorted_ind, cf1,cf2,cf3,3) # 견과류향, 시티로스팅 , 바디감(2)에 가까운걸 5개뽑아줘!!\n",
    "# #         coffee=similar_wondu['원두이름']\n",
    "#         #similar_wondu = find_sim_wondu(wondu, wondu_sim_sorted_ind, 'cf1','cf2',cf3,1) # 견과류향, 시티로스팅 , 바디감(2)에 가까운걸 5개뽑아줘!!\n",
    "#         #coffee=similar_wondu[['원두이름']]\n",
    "#      print('기모링')  \n",
    "#     #print(len(coffee.values))\n",
    "#     url = 'http://localhost:8081/muscle/musclevideo.do?result='+ #coffee.values[0]\n",
    "#     return redirect(url)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.config['JSON_AS_ASCII'] = False\n",
    "#     app.run(host='127.0.0.1', port='5002') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
